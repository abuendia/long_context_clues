{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import sklearn.utils\n",
    "from typing import List, Optional, Dict\n",
    "from sklearn.metrics import roc_auc_score, brier_score_loss\n",
    "import collections\n",
    "import warnings\n",
    "import pickle\n",
    "import femr.datasets\n",
    "import datetime\n",
    "from hf_ehr.config import EHRSHOT_LABELING_FUNCTION_2_PAPER_NAME\n",
    "from hf_ehr.notebooks.ehr_specific_properties.utils import (\n",
    "    get_labels_and_features, \n",
    "    get_patient_splits_by_idx\n",
    ")\n",
    "import scipy.stats\n",
    "from femr.labelers import load_labeled_patients, LabeledPatients\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning, module=\"sklearn.utils.validation\")\n",
    "\n",
    "PATH_TO_DATABASE: str = '/share/pi/nigam/mwornow/ehrshot-benchmark/EHRSHOT_ASSETS/femr/extract'\n",
    "PATH_TO_FEATURES_DIR: str = '/share/pi/nigam/mwornow/ehrshot-benchmark/EHRSHOT_ASSETS/features_ehrshot'\n",
    "PATH_TO_RESULTS_DIR: str = '/share/pi/nigam/users/migufuen/ehrshot-benchmark/EHRSHOT_ASSETS/results_ehrshot'\n",
    "PATH_TO_TOKENIZED_TIMELINES_DIR: str = '/share/pi/nigam/mwornow/ehrshot-benchmark/EHRSHOT_ASSETS/tokenized_timelines_ehrshot'\n",
    "PATH_TO_LABELS_DIR: str = '/share/pi/nigam/mwornow/ehrshot-benchmark/EHRSHOT_ASSETS/benchmark_ehrshot'\n",
    "PATH_TO_SPLIT_CSV: str = '/share/pi/nigam/mwornow/ehrshot-benchmark/EHRSHOT_ASSETS/splits_ehrshot/person_id_map.csv'\n",
    "femr_db = femr.datasets.PatientDatabase(PATH_TO_DATABASE)\n",
    "os.makedirs('../cache', exist_ok=True)\n",
    "\n",
    "IS_LOAD_FROM_CACHE: bool = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data\n",
    "\n",
    "First, we need to load all of the patient-level predictions / labels for every model and task.\n",
    "This takes ~30 min.\n",
    "\n",
    "1. Load list of task names, model names\n",
    "2. Load patient-level predictions for each (model, task)\n",
    "3. Load patient-level ground truth labels for each (task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasks: ['new_hypertension', 'guo_los', 'lab_hypoglycemia', 'new_lupus', 'lab_hyponatremia', 'new_pancan', 'lab_anemia', 'new_acutemi', 'guo_readmission', 'lab_thrombocytopenia', 'new_hyperlipidemia', 'new_celiac', 'lab_hyperkalemia', 'guo_icu']\n",
      "# of valid models: 17\n"
     ]
    }
   ],
   "source": [
    "# Get list of tasks\n",
    "valid_tasks = os.listdir(PATH_TO_RESULTS_DIR)\n",
    "valid_tasks.remove('chexpert')\n",
    "\n",
    "# Filter results to only valid models\n",
    "valid_models = [ \n",
    "    'llama-base-512--clmbr_train-tokens-total_nonPAD-ckpt_val=2000000000-persist_chunk:last_embed:last',\n",
    "    'llama-base-1024--clmbr_train-tokens-total_nonPAD-ckpt_val=2000000000-persist_chunk:last_embed:last',\n",
    "    'llama-base-2048--clmbr_train-tokens-total_nonPAD-ckpt_val=2000000000-persist_chunk:last_embed:last',\n",
    "    'llama-base-4096--clmbr_train-tokens-total_nonPAD-ckpt_val=2000000000-persist_chunk:last_embed:last',\n",
    "    'gpt2-base-512--clmbr_train-tokens-total_nonPAD-ckpt_val=2000000000-persist_chunk:last_embed:last',\n",
    "    'gpt2-base-1024--clmbr_train-tokens-total_nonPAD-ckpt_val=2000000000-persist_chunk:last_embed:last',\n",
    "    'gpt2-base-2048--clmbr_train-tokens-total_nonPAD-ckpt_val=2000000000-persist_chunk:last_embed:last',\n",
    "    'gpt2-base-4096--clmbr_train-tokens-total_nonPAD-ckpt_val=2000000000-persist_chunk:last_embed:last',\n",
    "    'hyena-large-1024--clmbr_train-tokens-total_nonPAD-ckpt_val=2000000000-persist_chunk:last_embed:last',\n",
    "    'hyena-large-4096--clmbr_train-tokens-total_nonPAD-ckpt_val=2000000000-persist_chunk:last_embed:last',\n",
    "    'hyena-large-8192--clmbr_train-tokens-total_nonPAD-ckpt_val=2000000000-persist_chunk:last_embed:last',\n",
    "    'hyena-large-16384--clmbr_train-tokens-total_nonPAD-ckpt_val=2000000000-persist_chunk:last_embed:last',\n",
    "    'mamba-tiny-1024--clmbr_train-tokens-total_nonPAD-ckpt_val=2000000000-persist_chunk:last_embed:last',\n",
    "    'mamba-tiny-4096--clmbr_train-tokens-total_nonPAD-ckpt_val=2000000000-persist_chunk:last_embed:last',\n",
    "    'mamba-tiny-8192--clmbr_train-tokens-total_nonPAD-ckpt_val=2000000000-persist_chunk:last_embed:last',\n",
    "    'mamba-tiny-16384--clmbr_train-tokens-total_nonPAD-ckpt_val=2000000000-persist_chunk:last_embed:last', \n",
    "    'clmbr',\n",
    "]\n",
    "print(\"Tasks:\", valid_tasks)\n",
    "print(\"# of valid models:\", len(valid_models))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading predictions from cache...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of (model, task) preds: 238\n"
     ]
    }
   ],
   "source": [
    "# Load patient-level predictions for each (model, task)\n",
    "predictions = {} # [key] = (model, task), [value] = df_preds\n",
    "\n",
    "if IS_LOAD_FROM_CACHE and os.path.exists('../cache/predictions.pkl'):\n",
    "    print(\"Loading predictions from cache...\")\n",
    "    predictions = pickle.load(open('../cache/predictions.pkl', 'rb'))\n",
    "else:\n",
    "    for task in tqdm(valid_tasks):\n",
    "        for model in valid_models:\n",
    "            path = os.path.join(PATH_TO_RESULTS_DIR, task, 'models', model, 'lr_lbfgs', f'subtask={task}', 'k=-1', 'preds.csv')\n",
    "            if not os.path.exists(path):\n",
    "                print(\"Missing path for \", model, task)\n",
    "            df_preds = pd.read_csv(path)\n",
    "            assert df_preds['replicate'].nunique() == 1, f\"Multiple replicates for {model}, {task}\"\n",
    "            predictions[(model, task)] = df_preds\n",
    "    # Save results to .pkl file\n",
    "    with open('../cache/predictions.pkl', 'wb') as f:\n",
    "        pickle.dump(predictions, f)\n",
    "print(\"# of (model, task) preds:\", len(predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading label data from cache...\n"
     ]
    }
   ],
   "source": [
    "# Load patient-level labels for each task\n",
    "# NOTE: Takes ~1 hr\n",
    "label_data = {} # [key] = task, [value] = {'times': label_times, 'values': label_values, 'patient_ids': patient_ids}\n",
    "\n",
    "if IS_LOAD_FROM_CACHE and os.path.exists('../cache/label_data.pkl'):\n",
    "    print(\"Loading label data from cache...\")\n",
    "    label_data = pickle.load(open('../cache/label_data.pkl', 'rb'))\n",
    "else:\n",
    "    for task in tqdm(valid_tasks):\n",
    "        # Load labeled patients for this task\n",
    "        LABELING_FUNCTION: str = task\n",
    "        PATH_TO_LABELED_PATIENTS: str =  os.path.join(PATH_TO_LABELS_DIR, LABELING_FUNCTION, 'labeled_patients.csv')\n",
    "        labeled_patients = femr.labelers.load_labeled_patients(PATH_TO_LABELED_PATIENTS)\n",
    "        \n",
    "        # Get features for patients\n",
    "        model: str = 'gpt2-base-512--clmbr_train-tokens-total_nonPAD-ckpt_val=2000000000-persist_chunk:last_embed:last'\n",
    "        patient_ids, label_values, label_times, feature_matrixes = get_labels_and_features(labeled_patients, \n",
    "                                                                                            PATH_TO_FEATURES_DIR, \n",
    "                                                                                            PATH_TO_TOKENIZED_TIMELINES_DIR,\n",
    "                                                                                            models_to_keep=[model,])\n",
    "        train_pids_idx, val_pids_idx, test_pids_idx = get_patient_splits_by_idx(PATH_TO_SPLIT_CSV, patient_ids)\n",
    "        label_times = label_times[train_pids_idx + val_pids_idx + test_pids_idx]\n",
    "        label_values = label_values[train_pids_idx + val_pids_idx + test_pids_idx]\n",
    "        patient_ids = patient_ids[train_pids_idx + val_pids_idx + test_pids_idx]\n",
    "        label_times = [ x.astype(datetime.datetime) for x in label_times ] # cast to Python datetime\n",
    "        label_data[task] = {'times': label_times, 'values': label_values, 'patient_ids': patient_ids}\n",
    "\n",
    "    # Save results to .pkl file\n",
    "    with open('../cache/label_data.pkl', 'wb') as f:\n",
    "        pickle.dump(label_data, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate CIs\n",
    "\n",
    "Calculate bootstrapped 95% CIs over the test set (one sample per patient).\n",
    "\n",
    "1. Generate 1000 bootstrapped resamples of patient IDs across all splits\n",
    "2. Loop through every (model, task) preds, limit to test set, loop through 1000 bootstrap weightings, loop through each stratification metric, recalculate quartiles of patients based on their metrics, and calculate Brier score for each quartile\n",
    "3. Calculate 95% CIs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do Bootstrapping of Brier Scores across Quartiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helpers\n",
    "strats = {\n",
    "    'inter_event_times': [ 'std' ],\n",
    "    'n_gram_count': ['rr_1'], \n",
    "    'timeline_lengths': ['n_events'],\n",
    "}\n",
    "path_to_ehrshot_metrics_dir: str = '/share/pi/nigam/mwornow/ehrshot-benchmark/ehrshot/stratify/'\n",
    "\n",
    "def weighted_quantile(values, quantiles, sample_weight=None, values_sorted=False):\n",
    "    values = np.array(values)\n",
    "    quantiles = np.array(quantiles)\n",
    "    if sample_weight is None:\n",
    "        sample_weight = np.ones(len(values))\n",
    "    sample_weight = np.array(sample_weight)\n",
    "    assert np.all(quantiles >= 0) and np.all(quantiles <= 1), \\\n",
    "        'quantiles should be in [0, 1]'\n",
    "\n",
    "    if not values_sorted:\n",
    "        sorter = np.argsort(values)\n",
    "        values = values[sorter]\n",
    "        sample_weight = sample_weight[sorter]\n",
    "\n",
    "    weighted_quantiles = np.cumsum(sample_weight) - 0.5 * sample_weight\n",
    "    weighted_quantiles /= np.sum(sample_weight)\n",
    "    return np.interp(quantiles, weighted_quantiles, values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of unique patients: 6275\n"
     ]
    }
   ],
   "source": [
    "# Get all patient IDs\n",
    "all_patients = np.sort(np.unique(np.concatenate([v['patient_ids'] for v in label_data.values()])))\n",
    "print(\"# of unique patients:\", len(all_patients))\n",
    "\n",
    "# Patient-level resampling across all patient IDs in train/val/test\n",
    "# Later, we limit to just test patient IDs per task\n",
    "bootstrap_weights = []\n",
    "np.random.seed(342342)\n",
    "for i in range(1000):\n",
    "    patient_sample = np.random.choice(list(range(len(all_patients))), len(all_patients), replace=True)\n",
    "    weights = np.zeros_like(all_patients, dtype=np.float32)\n",
    "    np.add.at(weights, patient_sample, 1)\n",
    "    assert np.mean(weights) == 1\n",
    "    bootstrap_weights.append(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Formatting\n",
    "def model_to_base(model: str) -> str:\n",
    "    return model.split('-')[0]\n",
    "def model_to_ctx(model: str) -> str:\n",
    "    return int(model.split('--')[0].split('-')[-1]) if model != 'clmbr' else 0\n",
    "def model_to_name(model: str) -> str:\n",
    "    return model.split('--')[0]\n",
    "\n",
    "def clean_df_briers(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "    df['model_name'] = df['model'].apply(model_to_name)\n",
    "    df['model_base'] = df['model'].apply(model_to_base)\n",
    "    df['ctx_length'] = df['model'].apply(model_to_ctx).astype(int)\n",
    "    if 'brier_true' in df.columns:\n",
    "        df['formatted_brier_ci_mean'] = df['brier_true'].apply(lambda x: f\"{x:.4f}\")\n",
    "        df['formatted_brier'] = df.apply(lambda x: f\"{x['brier_true']:.4f} ({x['brier_ci_025']:.4f}, {x['brier_ci_975']:.4f})\", axis=1)\n",
    "        df['formatted_brier_ci'] = df.apply(lambda x: f\"({x['brier_ci_025']:.4f}, {x['brier_ci_975']:.4f})\", axis=1)\n",
    "        df['is_brier_win'] = (df['brier_ci_025'] > 0) & (df['brier_ci_975'] > 0)\n",
    "        df['is_brier_stat_sig'] = (df['brier_ci_025'] > 0) | (df['brier_ci_975'] < 0)\n",
    "    if 'win_rate_true' in df.columns:\n",
    "        df['formatted_win_rate_ci_mean'] = df['win_rate_true'].apply(lambda x: f\"{x:.4f}\")\n",
    "        df['formatted_win_rate'] = df.apply(lambda x: f\"{x['win_rate_true']:.4f} ({x['win_rate_ci_025']:.4f}, {x['win_rate_ci_975']:.4f})\", axis=1)\n",
    "        df['formatted_win_rate'] = df.apply(lambda x: f\"{x['win_rate_true']:.4f} ({x['win_rate_ci_025']:.4f}, {x['win_rate_ci_975']:.4f})\", axis=1)\n",
    "        df['is_win_rate_win'] = (df['win_rate_ci_025'] > 0) & (df['win_rate_ci_975'] > 0)\n",
    "        df['is_win_rate_stat_sig'] = (df['win_rate_ci_025'] > 0) | (df['win_rate_ci_975'] < 0)\n",
    "    df = df[['model', 'model_name', 'model_base', 'ctx_length'] + [col for col in df.columns if col not in ['model', 'model_name', 'model_base', 'ctx_length']]]\n",
    "    df = df.sort_values(['model_base', 'ctx_length', ] + ([ 'task' ] if 'task' in df.columns else []))\n",
    "    return df\n",
    "\n",
    "def format_df_briers(df: pd.DataFrame, model_start: Optional[str] = None) -> pd.DataFrame:\n",
    "    if model_start is not None:\n",
    "        df = df[df['model'].str.startswith(model_start)]\n",
    "    df = df.drop(columns=['model', 'model_name', 'formatted_brier', 'brier_ci_mean', 'brier_ci_025', 'brier_ci_500', 'brier_ci_975', 'is_brier_win'], errors='ignore') \\\n",
    "        .rename(columns={   'model_base' : 'Model', \n",
    "                            'ctx_length' : 'Context Length', \n",
    "                            'formatted_brier_ci_mean' : r'$\\Delta$ over baseline', \n",
    "                            'formatted_brier_ci' : '95% CI', \n",
    "                            'formatted_win_rate_ci_mean' : r'Win Rate over baseline', \n",
    "                            'formatted_win_rate_ci' : 'Win Rate 95% CI', \n",
    "                            'is_brier_stat_sig' : 'Statistically Significant',\n",
    "                            'is_win_rate_stat_sig' : 'Win Rate Statistically Significant',\n",
    "                            'task' : 'Task'\n",
    "                }, errors='ignore') \\\n",
    "        .sort_values(['Model', 'Context Length',] + ([ 'Task' ] if 'task' in df.columns else []))\n",
    "    return df\n",
    "\n",
    "def format_df_briers_for_latex(df: pd.DataFrame, model_start: Optional[str] = None) -> str:\n",
    "    latex = format_df_briers(df, model_start).to_latex(index=False, escape=False)\n",
    "    for k, v in EHRSHOT_LABELING_FUNCTION_2_PAPER_NAME.items():\n",
    "        latex = latex.replace(k, v)\n",
    "    latex = latex.replace('False', '').replace('True', '\\checkmark')\n",
    "    return latex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "brier_scores_per_quartile = collections.defaultdict(list) # [key] = (model, task, strat, strat_col, quartile), [value] = brier's across 1k resamples for this quartile\n",
    "brier_scores_metadata_per_quartile = collections.defaultdict(list) # [key] = (model, task, strat, strat_col, quartile), [value] = metadata\n",
    "true_brier_scores_per_quartile = collections.defaultdict(int) # [key] = (model, task, strat, strat_col, quartile), [value] = True brier score for this model using original raw (non-bootstrapped) dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading brier_scores_per_quartile from cache...\n",
      "Loading true_brier_scores_per_quartile from cache...\n"
     ]
    }
   ],
   "source": [
    "# Calculate Brier scores for each (model, task, quartile) across 1k resamples\n",
    "if IS_LOAD_FROM_CACHE and os.path.exists('../cache/brier_scores_per_quartile.pkl') and os.path.exists('../cache/true_brier_scores_per_quartile.pkl') and os.path.exists('../cache/brier_scores_metadata_per_quartile.pkl'):\n",
    "    print(\"Loading brier_scores_per_quartile from cache...\")\n",
    "    brier_scores_per_quartile = pickle.load(open('../cache/brier_scores_per_quartile.pkl', 'rb'))\n",
    "    # print(\"Loading brier_scores_metadata_per_quartile from cache...\")\n",
    "    # brier_scores_metadata_per_quartile = pickle.load(open('../cache/brier_scores_metadata_per_quartile.pkl', 'rb'))\n",
    "    print(\"Loading true_brier_scores_per_quartile from cache...\")\n",
    "    true_brier_scores_per_quartile = pickle.load(open('../cache/true_brier_scores_per_quartile.pkl', 'rb'))\n",
    "else:\n",
    "    # Add metrics to each (model, task) predictions\n",
    "    for (model, task), df_preds in tqdm(predictions.items(), total=len(predictions)):\n",
    "        # Add (patient ID, label time) to df_preds to align with quartiles\n",
    "        df_preds['pid'] = label_data[task]['patient_ids']\n",
    "        df_preds['label_time'] = label_data[task]['times']\n",
    "\n",
    "        # Test split\n",
    "        df_preds = df_preds[df_preds['split'] == 'test']\n",
    "\n",
    "        # Merge patient IDs\n",
    "        for strat, strat_cols in strats.items():\n",
    "            df_metrics = pd.read_parquet(os.path.join(path_to_ehrshot_metrics_dir, f'df__{task}__{strat}__metrics.parquet'))\n",
    "\n",
    "            # If stratifying by inter-event times, need to pivot table since 'time' and 'metric' are separate columns\n",
    "            if strat == 'inter_event_times':\n",
    "                df_metrics = df_metrics.pivot_table(index=['pid', 'pid_idx', 'label_time', 'sub_task'], columns='metric', values='time').reset_index()\n",
    "\n",
    "            # Merge metrics with predictions\n",
    "            df_ = pd.merge(df_preds, df_metrics, on=['pid', 'label_time'])\n",
    "            if df_.shape[0] != df_preds.shape[0]:\n",
    "                print(f'{model} | {task} | {strat} | Number of rows in df does not match number of rows in df_preds: {df_.shape[0]} != {df_preds.shape[0]}')\n",
    "                \n",
    "            for strat_col in strat_cols:\n",
    "                if strat_col not in df_metrics.columns:\n",
    "                    raise ValueError(f'col={strat_col} not in df_metrics columns for strat={strat}.')\n",
    "\n",
    "                # Metric values\n",
    "                metric_values = df_[strat_col]\n",
    "\n",
    "                # Get test patient IDs\n",
    "                patient_ids = df_['pid'].values\n",
    "                patient_id_indices = np.searchsorted(all_patients, patient_ids)\n",
    "                assert np.all(patient_ids == all_patients[patient_id_indices])\n",
    "                \n",
    "                # Calculate \"true\" Brier scores on non-bootstrapped dataset\n",
    "                df_['quartile'] = pd.qcut(df_[strat_col].fillna(0).rank(method='min'), 4, labels=False)\n",
    "                assert set(df_['quartile'].unique()) == {0, 1, 2, 3}, f'Quartiles not 0, 1, 2, 3: {set(df_[\"quartile\"].unique())}'\n",
    "                for quartile in range(4):\n",
    "                    # Limit to this quartile\n",
    "                    df_quartile = df_[df_['quartile'] == quartile]\n",
    "                    # Labels / Preds\n",
    "                    y = df_quartile['y'].values.astype(int)\n",
    "                    pred_proba = df_quartile['pred_proba'].values\n",
    "                    # Calculate Brier score\n",
    "                    brier = brier_score_loss(y, pred_proba)\n",
    "                    true_brier_scores_per_quartile[(model, task, strat, strat_col, quartile)] = brier\n",
    "\n",
    "                # Do bootstraps\n",
    "                for weights in bootstrap_weights:\n",
    "                    weights = weights[patient_id_indices]\n",
    "                    assert weights.shape[0] == df_.shape[0] and weights.shape[0] == metric_values.shape[0], f\"Error - weights shape: {weights.shape[0]}, df shape: {df_.shape[0]}, metric_values shape: {metric_values.shape[0]}\"\n",
    "\n",
    "                    # Calculate quartiles\n",
    "                    quantile_cutoffs = weighted_quantile(metric_values, [0.25, .5, .75, 1], weights)\n",
    "                    df_['quartile'] = np.searchsorted(quantile_cutoffs, metric_values)\n",
    "                    df_['weight'] = weights\n",
    "                    assert set(df_['quartile'].unique()) == {0, 1, 2, 3}, f'Quartiles not 0, 1, 2, 3: {set(df_metrics[\"quartile\"].unique())}'\n",
    "\n",
    "                    # Calculate Brier scores\n",
    "                    for quartile in range(4):\n",
    "                        # Limit to this quartile\n",
    "                        df_quartile = df_[df_['quartile'] == quartile]\n",
    "                        # Labels / Preds\n",
    "                        y = df_quartile['y'].values.astype(int)\n",
    "                        pred_proba = df_quartile['pred_proba'].values\n",
    "                        sample_weight = df_quartile['weight'].values\n",
    "                        # Calculate Brier score\n",
    "                        brier = brier_score_loss(y, pred_proba, sample_weight=sample_weight)\n",
    "                        brier_scores_per_quartile[(model, task, strat, strat_col, quartile)].append(brier)\n",
    "                        brier_scores_metadata_per_quartile[(model, task, strat, strat_col, quartile)].append({\n",
    "                            'brier' : ((y - pred_proba) ** 2).astype(np.float32),\n",
    "                            'sample_weight' : sample_weight.astype(np.int8),\n",
    "                        })\n",
    "    # Save results to .pkl file\n",
    "    with open('../cache/brier_scores_per_quartile.pkl', 'wb') as f:\n",
    "        pickle.dump(brier_scores_per_quartile, f)\n",
    "    with open('../cache/true_brier_scores_per_quartile.pkl', 'wb') as f:\n",
    "        pickle.dump(true_brier_scores_per_quartile, f)\n",
    "    with open('../cache/brier_scores_metadata_per_quartile.pkl', 'wb') as f:\n",
    "        pickle.dump(brier_scores_metadata_per_quartile, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task-Level CIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>task</th>\n",
       "      <th>quartile</th>\n",
       "      <th>strat</th>\n",
       "      <th>strat_col</th>\n",
       "      <th>brier_true</th>\n",
       "      <th>brier_ci_mean</th>\n",
       "      <th>brier_ci_025</th>\n",
       "      <th>brier_ci_500</th>\n",
       "      <th>brier_ci_975</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2844</th>\n",
       "      <td>clmbr</td>\n",
       "      <td>guo_icu</td>\n",
       "      <td>0</td>\n",
       "      <td>inter_event_times</td>\n",
       "      <td>std</td>\n",
       "      <td>0.035984</td>\n",
       "      <td>0.035149</td>\n",
       "      <td>0.019668</td>\n",
       "      <td>0.035239</td>\n",
       "      <td>0.052189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2848</th>\n",
       "      <td>clmbr</td>\n",
       "      <td>guo_icu</td>\n",
       "      <td>0</td>\n",
       "      <td>n_gram_count</td>\n",
       "      <td>rr_1</td>\n",
       "      <td>0.040230</td>\n",
       "      <td>0.039553</td>\n",
       "      <td>0.026063</td>\n",
       "      <td>0.039179</td>\n",
       "      <td>0.053784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2852</th>\n",
       "      <td>clmbr</td>\n",
       "      <td>guo_icu</td>\n",
       "      <td>0</td>\n",
       "      <td>timeline_lengths</td>\n",
       "      <td>n_events</td>\n",
       "      <td>0.044137</td>\n",
       "      <td>0.044539</td>\n",
       "      <td>0.030298</td>\n",
       "      <td>0.044418</td>\n",
       "      <td>0.059930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2845</th>\n",
       "      <td>clmbr</td>\n",
       "      <td>guo_icu</td>\n",
       "      <td>1</td>\n",
       "      <td>inter_event_times</td>\n",
       "      <td>std</td>\n",
       "      <td>0.023934</td>\n",
       "      <td>0.024645</td>\n",
       "      <td>0.014234</td>\n",
       "      <td>0.024329</td>\n",
       "      <td>0.037353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2849</th>\n",
       "      <td>clmbr</td>\n",
       "      <td>guo_icu</td>\n",
       "      <td>1</td>\n",
       "      <td>n_gram_count</td>\n",
       "      <td>rr_1</td>\n",
       "      <td>0.032956</td>\n",
       "      <td>0.033599</td>\n",
       "      <td>0.020306</td>\n",
       "      <td>0.033245</td>\n",
       "      <td>0.048665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1194</th>\n",
       "      <td>mamba-tiny-8192--clmbr_train-tokens-total_nonP...</td>\n",
       "      <td>new_pancan</td>\n",
       "      <td>2</td>\n",
       "      <td>n_gram_count</td>\n",
       "      <td>rr_1</td>\n",
       "      <td>0.026120</td>\n",
       "      <td>0.026648</td>\n",
       "      <td>0.013950</td>\n",
       "      <td>0.026183</td>\n",
       "      <td>0.041951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1198</th>\n",
       "      <td>mamba-tiny-8192--clmbr_train-tokens-total_nonP...</td>\n",
       "      <td>new_pancan</td>\n",
       "      <td>2</td>\n",
       "      <td>timeline_lengths</td>\n",
       "      <td>n_events</td>\n",
       "      <td>0.024836</td>\n",
       "      <td>0.023678</td>\n",
       "      <td>0.014339</td>\n",
       "      <td>0.023457</td>\n",
       "      <td>0.035831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1191</th>\n",
       "      <td>mamba-tiny-8192--clmbr_train-tokens-total_nonP...</td>\n",
       "      <td>new_pancan</td>\n",
       "      <td>3</td>\n",
       "      <td>inter_event_times</td>\n",
       "      <td>std</td>\n",
       "      <td>0.026012</td>\n",
       "      <td>0.025991</td>\n",
       "      <td>0.015477</td>\n",
       "      <td>0.025312</td>\n",
       "      <td>0.040845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1195</th>\n",
       "      <td>mamba-tiny-8192--clmbr_train-tokens-total_nonP...</td>\n",
       "      <td>new_pancan</td>\n",
       "      <td>3</td>\n",
       "      <td>n_gram_count</td>\n",
       "      <td>rr_1</td>\n",
       "      <td>0.014126</td>\n",
       "      <td>0.014282</td>\n",
       "      <td>0.005617</td>\n",
       "      <td>0.013576</td>\n",
       "      <td>0.026770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1199</th>\n",
       "      <td>mamba-tiny-8192--clmbr_train-tokens-total_nonP...</td>\n",
       "      <td>new_pancan</td>\n",
       "      <td>3</td>\n",
       "      <td>timeline_lengths</td>\n",
       "      <td>n_events</td>\n",
       "      <td>0.021365</td>\n",
       "      <td>0.022951</td>\n",
       "      <td>0.010370</td>\n",
       "      <td>0.022282</td>\n",
       "      <td>0.038982</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2856 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  model        task  quartile  \\\n",
       "2844                                              clmbr     guo_icu         0   \n",
       "2848                                              clmbr     guo_icu         0   \n",
       "2852                                              clmbr     guo_icu         0   \n",
       "2845                                              clmbr     guo_icu         1   \n",
       "2849                                              clmbr     guo_icu         1   \n",
       "...                                                 ...         ...       ...   \n",
       "1194  mamba-tiny-8192--clmbr_train-tokens-total_nonP...  new_pancan         2   \n",
       "1198  mamba-tiny-8192--clmbr_train-tokens-total_nonP...  new_pancan         2   \n",
       "1191  mamba-tiny-8192--clmbr_train-tokens-total_nonP...  new_pancan         3   \n",
       "1195  mamba-tiny-8192--clmbr_train-tokens-total_nonP...  new_pancan         3   \n",
       "1199  mamba-tiny-8192--clmbr_train-tokens-total_nonP...  new_pancan         3   \n",
       "\n",
       "                  strat strat_col  brier_true  brier_ci_mean  brier_ci_025  \\\n",
       "2844  inter_event_times       std    0.035984       0.035149      0.019668   \n",
       "2848       n_gram_count      rr_1    0.040230       0.039553      0.026063   \n",
       "2852   timeline_lengths  n_events    0.044137       0.044539      0.030298   \n",
       "2845  inter_event_times       std    0.023934       0.024645      0.014234   \n",
       "2849       n_gram_count      rr_1    0.032956       0.033599      0.020306   \n",
       "...                 ...       ...         ...            ...           ...   \n",
       "1194       n_gram_count      rr_1    0.026120       0.026648      0.013950   \n",
       "1198   timeline_lengths  n_events    0.024836       0.023678      0.014339   \n",
       "1191  inter_event_times       std    0.026012       0.025991      0.015477   \n",
       "1195       n_gram_count      rr_1    0.014126       0.014282      0.005617   \n",
       "1199   timeline_lengths  n_events    0.021365       0.022951      0.010370   \n",
       "\n",
       "      brier_ci_500  brier_ci_975  \n",
       "2844      0.035239      0.052189  \n",
       "2848      0.039179      0.053784  \n",
       "2852      0.044418      0.059930  \n",
       "2845      0.024329      0.037353  \n",
       "2849      0.033245      0.048665  \n",
       "...            ...           ...  \n",
       "1194      0.026183      0.041951  \n",
       "1198      0.023457      0.035831  \n",
       "1191      0.025312      0.040845  \n",
       "1195      0.013576      0.026770  \n",
       "1199      0.022282      0.038982  \n",
       "\n",
       "[2856 rows x 10 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate task-level Brier CIs\n",
    "df_brier_cis = []\n",
    "for key in brier_scores_per_quartile.keys():\n",
    "    model, task, strat, strat_col, quartile = key\n",
    "    scores = brier_scores_per_quartile[key]\n",
    "    df_brier_cis.append({\n",
    "        'model' : model,\n",
    "        'task' : task,\n",
    "        'quartile' : quartile,\n",
    "        'strat' : strat,\n",
    "        'strat_col' : strat_col,\n",
    "        'brier_true' : true_brier_scores_per_quartile[key],\n",
    "        'brier_ci_mean' : np.mean(scores),\n",
    "        'brier_ci_025' : np.percentile(scores, 2.5),\n",
    "        'brier_ci_500' : np.percentile(scores, 50),\n",
    "        'brier_ci_975' : np.percentile(scores, 97.5),\n",
    "    })\n",
    "df_brier_cis = pd.DataFrame(df_brier_cis).sort_values(['model', 'task', 'quartile'])\n",
    "df_brier_cis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model-level CIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1258, 2195, 100568, 2243, 67028, 2220, 58155, 2127, 2189, 56338, 1317, 2222, 63653, 2037]\n"
     ]
    }
   ],
   "source": [
    "# Get test PIDs for each task\n",
    "task_2_test_pids = {}\n",
    "for (model, task), df_preds in predictions.items():\n",
    "    if task in task_2_test_pids:\n",
    "        continue\n",
    "    assert label_data[task]['patient_ids'].shape[0] == len(label_data[task]['times'])\n",
    "    df_preds['pid'] = label_data[task]['patient_ids']\n",
    "    df_preds['label_time'] = label_data[task]['times']\n",
    "    test_pids = df_preds[df_preds['split'] == 'test']\n",
    "    task_2_test_pids[task] = test_pids['pid']\n",
    "    if len(task_2_test_pids[task]) == len(valid_tasks):\n",
    "        break\n",
    "print([ len(task_2_test_pids[task]) for task in valid_tasks ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>task</th>\n",
       "      <th>strat</th>\n",
       "      <th>strat_col</th>\n",
       "      <th>quartile</th>\n",
       "      <th>brier_true</th>\n",
       "      <th>brier_ci_mean</th>\n",
       "      <th>brier_ci_025</th>\n",
       "      <th>brier_ci_500</th>\n",
       "      <th>brier_ci_975</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>clmbr</td>\n",
       "      <td>all</td>\n",
       "      <td>inter_event_times</td>\n",
       "      <td>std</td>\n",
       "      <td>0</td>\n",
       "      <td>0.068110</td>\n",
       "      <td>0.068768</td>\n",
       "      <td>0.061678</td>\n",
       "      <td>0.068846</td>\n",
       "      <td>0.075391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>clmbr</td>\n",
       "      <td>all</td>\n",
       "      <td>n_gram_count</td>\n",
       "      <td>rr_1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.064749</td>\n",
       "      <td>0.064870</td>\n",
       "      <td>0.060491</td>\n",
       "      <td>0.064838</td>\n",
       "      <td>0.069401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>clmbr</td>\n",
       "      <td>all</td>\n",
       "      <td>timeline_lengths</td>\n",
       "      <td>n_events</td>\n",
       "      <td>0</td>\n",
       "      <td>0.070006</td>\n",
       "      <td>0.069885</td>\n",
       "      <td>0.065220</td>\n",
       "      <td>0.069992</td>\n",
       "      <td>0.074372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>clmbr</td>\n",
       "      <td>all</td>\n",
       "      <td>inter_event_times</td>\n",
       "      <td>std</td>\n",
       "      <td>1</td>\n",
       "      <td>0.073972</td>\n",
       "      <td>0.073590</td>\n",
       "      <td>0.068396</td>\n",
       "      <td>0.073618</td>\n",
       "      <td>0.078932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>clmbr</td>\n",
       "      <td>all</td>\n",
       "      <td>n_gram_count</td>\n",
       "      <td>rr_1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.071764</td>\n",
       "      <td>0.071972</td>\n",
       "      <td>0.067029</td>\n",
       "      <td>0.071968</td>\n",
       "      <td>0.076659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>mamba-tiny-8192--clmbr_train-tokens-total_nonP...</td>\n",
       "      <td>all</td>\n",
       "      <td>n_gram_count</td>\n",
       "      <td>rr_1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.070774</td>\n",
       "      <td>0.071371</td>\n",
       "      <td>0.065286</td>\n",
       "      <td>0.071519</td>\n",
       "      <td>0.077010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>mamba-tiny-8192--clmbr_train-tokens-total_nonP...</td>\n",
       "      <td>all</td>\n",
       "      <td>timeline_lengths</td>\n",
       "      <td>n_events</td>\n",
       "      <td>2</td>\n",
       "      <td>0.073094</td>\n",
       "      <td>0.072354</td>\n",
       "      <td>0.067307</td>\n",
       "      <td>0.072333</td>\n",
       "      <td>0.077191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>mamba-tiny-8192--clmbr_train-tokens-total_nonP...</td>\n",
       "      <td>all</td>\n",
       "      <td>inter_event_times</td>\n",
       "      <td>std</td>\n",
       "      <td>3</td>\n",
       "      <td>0.073400</td>\n",
       "      <td>0.073705</td>\n",
       "      <td>0.069028</td>\n",
       "      <td>0.073706</td>\n",
       "      <td>0.078748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>mamba-tiny-8192--clmbr_train-tokens-total_nonP...</td>\n",
       "      <td>all</td>\n",
       "      <td>n_gram_count</td>\n",
       "      <td>rr_1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.075551</td>\n",
       "      <td>0.075227</td>\n",
       "      <td>0.069464</td>\n",
       "      <td>0.075280</td>\n",
       "      <td>0.081099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>mamba-tiny-8192--clmbr_train-tokens-total_nonP...</td>\n",
       "      <td>all</td>\n",
       "      <td>timeline_lengths</td>\n",
       "      <td>n_events</td>\n",
       "      <td>3</td>\n",
       "      <td>0.068306</td>\n",
       "      <td>0.069554</td>\n",
       "      <td>0.062388</td>\n",
       "      <td>0.069526</td>\n",
       "      <td>0.076128</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>204 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 model task  \\\n",
       "64                                               clmbr  all   \n",
       "132                                              clmbr  all   \n",
       "200                                              clmbr  all   \n",
       "65                                               clmbr  all   \n",
       "133                                              clmbr  all   \n",
       "..                                                 ...  ...   \n",
       "126  mamba-tiny-8192--clmbr_train-tokens-total_nonP...  all   \n",
       "194  mamba-tiny-8192--clmbr_train-tokens-total_nonP...  all   \n",
       "59   mamba-tiny-8192--clmbr_train-tokens-total_nonP...  all   \n",
       "127  mamba-tiny-8192--clmbr_train-tokens-total_nonP...  all   \n",
       "195  mamba-tiny-8192--clmbr_train-tokens-total_nonP...  all   \n",
       "\n",
       "                 strat strat_col  quartile  brier_true  brier_ci_mean  \\\n",
       "64   inter_event_times       std         0    0.068110       0.068768   \n",
       "132       n_gram_count      rr_1         0    0.064749       0.064870   \n",
       "200   timeline_lengths  n_events         0    0.070006       0.069885   \n",
       "65   inter_event_times       std         1    0.073972       0.073590   \n",
       "133       n_gram_count      rr_1         1    0.071764       0.071972   \n",
       "..                 ...       ...       ...         ...            ...   \n",
       "126       n_gram_count      rr_1         2    0.070774       0.071371   \n",
       "194   timeline_lengths  n_events         2    0.073094       0.072354   \n",
       "59   inter_event_times       std         3    0.073400       0.073705   \n",
       "127       n_gram_count      rr_1         3    0.075551       0.075227   \n",
       "195   timeline_lengths  n_events         3    0.068306       0.069554   \n",
       "\n",
       "     brier_ci_025  brier_ci_500  brier_ci_975  \n",
       "64       0.061678      0.068846      0.075391  \n",
       "132      0.060491      0.064838      0.069401  \n",
       "200      0.065220      0.069992      0.074372  \n",
       "65       0.068396      0.073618      0.078932  \n",
       "133      0.067029      0.071968      0.076659  \n",
       "..            ...           ...           ...  \n",
       "126      0.065286      0.071519      0.077010  \n",
       "194      0.067307      0.072333      0.077191  \n",
       "59       0.069028      0.073706      0.078748  \n",
       "127      0.069464      0.075280      0.081099  \n",
       "195      0.062388      0.069526      0.076128  \n",
       "\n",
       "[204 rows x 10 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reweight each bootstrap by the number of labels in the task\n",
    "n_labels_per_task = []\n",
    "for weights in bootstrap_weights:\n",
    "    weights_per_task = [\n",
    "        weights[np.searchsorted(all_patients, task_2_test_pids[task])] \n",
    "        for task in valid_tasks\n",
    "    ]\n",
    "    n_labels_per_task.append([w.sum() for w in weights_per_task])\n",
    "n_labels_per_task = np.array(n_labels_per_task).T\n",
    "assert n_labels_per_task.shape == (14, 1000)\n",
    "\n",
    "# Calculate model-level Brier CIs\n",
    "df_brier_model_cis = []\n",
    "for strat, strat_cols in strats.items():\n",
    "    for strat_col in strat_cols:\n",
    "        for model in valid_models:\n",
    "            for quartile in range(4):\n",
    "                ci_scores = [] # scores for this quartile, averaged across all tasks\n",
    "                true_scores = [] # true scores for this quartile, averaged across all tasks\n",
    "                for task in valid_tasks:\n",
    "                    ci_scores.append(brier_scores_per_quartile[(model, task, strat, strat_col, quartile)]) # each is 1 x 1000\n",
    "                    true_scores.append(true_brier_scores_per_quartile[(model, task, strat, strat_col, quartile)]) # each is 1 x 1\n",
    "                # Raw scores\n",
    "                scores = np.vstack(ci_scores) # 14 x 1000\n",
    "                assert scores.shape == (14, 1000)\n",
    "                # Macro-average across tasks\n",
    "                scores = np.mean(scores, axis=0)\n",
    "                # Micro-average across tasks\n",
    "                # scores = np.average(scores, axis=0, weights=n_labels_per_task)\n",
    "                df_brier_model_cis.append({\n",
    "                    'model' : model,\n",
    "                    'task' : 'all',\n",
    "                    'strat' : strat,\n",
    "                    'strat_col' : strat_col,\n",
    "                    'quartile' : quartile,\n",
    "                    'brier_true' : np.mean(true_scores),\n",
    "                    'brier_ci_mean' : np.mean(scores),\n",
    "                    'brier_ci_025' : np.percentile(scores, 2.5),\n",
    "                    'brier_ci_500' : np.percentile(scores, 50),\n",
    "                    'brier_ci_975' : np.percentile(scores, 97.5),\n",
    "                })\n",
    "df_brier_model_cis = pd.DataFrame(df_brier_model_cis).sort_values(['model', 'quartile'])\n",
    "df_brier_model_cis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>quartile</th>\n",
       "      <th>model</th>\n",
       "      <th>model_base</th>\n",
       "      <th>ctx_length</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gpt2-base-512--clmbr_train-tokens-total_nonPAD...</td>\n",
       "      <td>gpt2</td>\n",
       "      <td>512</td>\n",
       "      <td>0.0654 (0.0591, 0.0723)</td>\n",
       "      <td>0.0693 (0.0641, 0.0743)</td>\n",
       "      <td>0.0703 (0.0656, 0.0752)</td>\n",
       "      <td>0.0736 (0.0692, 0.0786)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gpt2-base-4096--clmbr_train-tokens-total_nonPA...</td>\n",
       "      <td>gpt2</td>\n",
       "      <td>4096</td>\n",
       "      <td>0.0653 (0.0594, 0.0722)</td>\n",
       "      <td>0.0699 (0.0646, 0.0747)</td>\n",
       "      <td>0.0701 (0.0656, 0.0749)</td>\n",
       "      <td>0.0759 (0.0715, 0.0812)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>hyena-large-1024--clmbr_train-tokens-total_non...</td>\n",
       "      <td>hyena</td>\n",
       "      <td>1024</td>\n",
       "      <td>0.0666 (0.0604, 0.0736)</td>\n",
       "      <td>0.0702 (0.0649, 0.0748)</td>\n",
       "      <td>0.0692 (0.0646, 0.0739)</td>\n",
       "      <td>0.0751 (0.0704, 0.0804)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>hyena-large-16384--clmbr_train-tokens-total_no...</td>\n",
       "      <td>hyena</td>\n",
       "      <td>16384</td>\n",
       "      <td>0.0698 (0.0641, 0.0767)</td>\n",
       "      <td>0.0755 (0.0702, 0.0803)</td>\n",
       "      <td>0.0788 (0.0740, 0.0837)</td>\n",
       "      <td>0.0853 (0.0804, 0.0907)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>llama-base-512--clmbr_train-tokens-total_nonPA...</td>\n",
       "      <td>llama</td>\n",
       "      <td>512</td>\n",
       "      <td>0.0694 (0.0644, 0.0757)</td>\n",
       "      <td>0.0730 (0.0679, 0.0775)</td>\n",
       "      <td>0.0713 (0.0669, 0.0757)</td>\n",
       "      <td>0.0749 (0.0708, 0.0797)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>llama-base-4096--clmbr_train-tokens-total_nonP...</td>\n",
       "      <td>llama</td>\n",
       "      <td>4096</td>\n",
       "      <td>0.0664 (0.0604, 0.0733)</td>\n",
       "      <td>0.0705 (0.0655, 0.0753)</td>\n",
       "      <td>0.0694 (0.0650, 0.0744)</td>\n",
       "      <td>0.0740 (0.0695, 0.0792)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>mamba-tiny-1024--clmbr_train-tokens-total_nonP...</td>\n",
       "      <td>mamba</td>\n",
       "      <td>1024</td>\n",
       "      <td>0.0693 (0.0632, 0.0759)</td>\n",
       "      <td>0.0729 (0.0678, 0.0779)</td>\n",
       "      <td>0.0731 (0.0685, 0.0779)</td>\n",
       "      <td>0.0764 (0.0718, 0.0816)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>mamba-tiny-16384--clmbr_train-tokens-total_non...</td>\n",
       "      <td>mamba</td>\n",
       "      <td>16384</td>\n",
       "      <td>0.0641 (0.0588, 0.0704)</td>\n",
       "      <td>0.0678 (0.0628, 0.0728)</td>\n",
       "      <td>0.0679 (0.0635, 0.0729)</td>\n",
       "      <td>0.0723 (0.0680, 0.0773)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "quartile                                              model model_base  \\\n",
       "4         gpt2-base-512--clmbr_train-tokens-total_nonPAD...       gpt2   \n",
       "3         gpt2-base-4096--clmbr_train-tokens-total_nonPA...       gpt2   \n",
       "5         hyena-large-1024--clmbr_train-tokens-total_non...      hyena   \n",
       "6         hyena-large-16384--clmbr_train-tokens-total_no...      hyena   \n",
       "12        llama-base-512--clmbr_train-tokens-total_nonPA...      llama   \n",
       "11        llama-base-4096--clmbr_train-tokens-total_nonP...      llama   \n",
       "13        mamba-tiny-1024--clmbr_train-tokens-total_nonP...      mamba   \n",
       "14        mamba-tiny-16384--clmbr_train-tokens-total_non...      mamba   \n",
       "\n",
       "quartile  ctx_length                        0                        1  \\\n",
       "4                512  0.0654 (0.0591, 0.0723)  0.0693 (0.0641, 0.0743)   \n",
       "3               4096  0.0653 (0.0594, 0.0722)  0.0699 (0.0646, 0.0747)   \n",
       "5               1024  0.0666 (0.0604, 0.0736)  0.0702 (0.0649, 0.0748)   \n",
       "6              16384  0.0698 (0.0641, 0.0767)  0.0755 (0.0702, 0.0803)   \n",
       "12               512  0.0694 (0.0644, 0.0757)  0.0730 (0.0679, 0.0775)   \n",
       "11              4096  0.0664 (0.0604, 0.0733)  0.0705 (0.0655, 0.0753)   \n",
       "13              1024  0.0693 (0.0632, 0.0759)  0.0729 (0.0678, 0.0779)   \n",
       "14             16384  0.0641 (0.0588, 0.0704)  0.0678 (0.0628, 0.0728)   \n",
       "\n",
       "quartile                        2                        3  \n",
       "4         0.0703 (0.0656, 0.0752)  0.0736 (0.0692, 0.0786)  \n",
       "3         0.0701 (0.0656, 0.0749)  0.0759 (0.0715, 0.0812)  \n",
       "5         0.0692 (0.0646, 0.0739)  0.0751 (0.0704, 0.0804)  \n",
       "6         0.0788 (0.0740, 0.0837)  0.0853 (0.0804, 0.0907)  \n",
       "12        0.0713 (0.0669, 0.0757)  0.0749 (0.0708, 0.0797)  \n",
       "11        0.0694 (0.0650, 0.0744)  0.0740 (0.0695, 0.0792)  \n",
       "13        0.0731 (0.0685, 0.0779)  0.0764 (0.0718, 0.0816)  \n",
       "14        0.0679 (0.0635, 0.0729)  0.0723 (0.0680, 0.0773)  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_irregularity = clean_df_briers(df_brier_model_cis[df_brier_model_cis['strat_col'] == 'std'])\n",
    "# Take the 'quartile' column and give each unique value its own column. Use the `formatted_brier` column as the values.\n",
    "df_irregularity = df_irregularity.pivot(index=['model', 'model_base', 'ctx_length'], columns='quartile', values='formatted_brier').reset_index().sort_values(['model_base', 'ctx_length'])\n",
    "\n",
    "# Limit to first / last for clarity\n",
    "df_model_latex = df_irregularity[\n",
    "    (\n",
    "        (df_irregularity['model_base'].isin(['mamba', 'hyena']) & df_irregularity['ctx_length'].isin([1024, 16384]))\n",
    "        | (df_irregularity['model_base'].isin(['gpt2', 'llama']) & df_irregularity['ctx_length'].isin([512, 4096]))\n",
    "    )\n",
    "]\n",
    "df_model_latex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>quartile</th>\n",
       "      <th>model</th>\n",
       "      <th>model_base</th>\n",
       "      <th>ctx_length</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gpt2-base-512--clmbr_train-tokens-total_nonPAD...</td>\n",
       "      <td>gpt2</td>\n",
       "      <td>512</td>\n",
       "      <td>0.0619 (0.0579, 0.0660)</td>\n",
       "      <td>0.0691 (0.0646, 0.0741)</td>\n",
       "      <td>0.0710 (0.0655, 0.0775)</td>\n",
       "      <td>0.0765 (0.0706, 0.0818)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gpt2-base-4096--clmbr_train-tokens-total_nonPA...</td>\n",
       "      <td>gpt2</td>\n",
       "      <td>4096</td>\n",
       "      <td>0.0643 (0.0601, 0.0691)</td>\n",
       "      <td>0.0692 (0.0648, 0.0740)</td>\n",
       "      <td>0.0711 (0.0658, 0.0774)</td>\n",
       "      <td>0.0765 (0.0704, 0.0817)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>hyena-large-1024--clmbr_train-tokens-total_non...</td>\n",
       "      <td>hyena</td>\n",
       "      <td>1024</td>\n",
       "      <td>0.0636 (0.0594, 0.0680)</td>\n",
       "      <td>0.0681 (0.0636, 0.0728)</td>\n",
       "      <td>0.0718 (0.0661, 0.0786)</td>\n",
       "      <td>0.0776 (0.0716, 0.0829)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>hyena-large-16384--clmbr_train-tokens-total_no...</td>\n",
       "      <td>hyena</td>\n",
       "      <td>16384</td>\n",
       "      <td>0.0733 (0.0688, 0.0777)</td>\n",
       "      <td>0.0759 (0.0715, 0.0812)</td>\n",
       "      <td>0.0780 (0.0724, 0.0839)</td>\n",
       "      <td>0.0822 (0.0762, 0.0879)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>llama-base-512--clmbr_train-tokens-total_nonPA...</td>\n",
       "      <td>llama</td>\n",
       "      <td>512</td>\n",
       "      <td>0.0640 (0.0600, 0.0684)</td>\n",
       "      <td>0.0710 (0.0665, 0.0758)</td>\n",
       "      <td>0.0743 (0.0688, 0.0807)</td>\n",
       "      <td>0.0792 (0.0730, 0.0846)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>llama-base-4096--clmbr_train-tokens-total_nonP...</td>\n",
       "      <td>llama</td>\n",
       "      <td>4096</td>\n",
       "      <td>0.0627 (0.0587, 0.0670)</td>\n",
       "      <td>0.0687 (0.0644, 0.0735)</td>\n",
       "      <td>0.0721 (0.0666, 0.0785)</td>\n",
       "      <td>0.0770 (0.0711, 0.0824)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>mamba-tiny-1024--clmbr_train-tokens-total_nonP...</td>\n",
       "      <td>mamba</td>\n",
       "      <td>1024</td>\n",
       "      <td>0.0644 (0.0601, 0.0688)</td>\n",
       "      <td>0.0737 (0.0691, 0.0785)</td>\n",
       "      <td>0.0744 (0.0687, 0.0811)</td>\n",
       "      <td>0.0790 (0.0732, 0.0847)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>mamba-tiny-16384--clmbr_train-tokens-total_non...</td>\n",
       "      <td>mamba</td>\n",
       "      <td>16384</td>\n",
       "      <td>0.0605 (0.0567, 0.0648)</td>\n",
       "      <td>0.0670 (0.0625, 0.0720)</td>\n",
       "      <td>0.0700 (0.0650, 0.0757)</td>\n",
       "      <td>0.0746 (0.0687, 0.0801)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "quartile                                              model model_base  \\\n",
       "4         gpt2-base-512--clmbr_train-tokens-total_nonPAD...       gpt2   \n",
       "3         gpt2-base-4096--clmbr_train-tokens-total_nonPA...       gpt2   \n",
       "5         hyena-large-1024--clmbr_train-tokens-total_non...      hyena   \n",
       "6         hyena-large-16384--clmbr_train-tokens-total_no...      hyena   \n",
       "12        llama-base-512--clmbr_train-tokens-total_nonPA...      llama   \n",
       "11        llama-base-4096--clmbr_train-tokens-total_nonP...      llama   \n",
       "13        mamba-tiny-1024--clmbr_train-tokens-total_nonP...      mamba   \n",
       "14        mamba-tiny-16384--clmbr_train-tokens-total_non...      mamba   \n",
       "\n",
       "quartile  ctx_length                        0                        1  \\\n",
       "4                512  0.0619 (0.0579, 0.0660)  0.0691 (0.0646, 0.0741)   \n",
       "3               4096  0.0643 (0.0601, 0.0691)  0.0692 (0.0648, 0.0740)   \n",
       "5               1024  0.0636 (0.0594, 0.0680)  0.0681 (0.0636, 0.0728)   \n",
       "6              16384  0.0733 (0.0688, 0.0777)  0.0759 (0.0715, 0.0812)   \n",
       "12               512  0.0640 (0.0600, 0.0684)  0.0710 (0.0665, 0.0758)   \n",
       "11              4096  0.0627 (0.0587, 0.0670)  0.0687 (0.0644, 0.0735)   \n",
       "13              1024  0.0644 (0.0601, 0.0688)  0.0737 (0.0691, 0.0785)   \n",
       "14             16384  0.0605 (0.0567, 0.0648)  0.0670 (0.0625, 0.0720)   \n",
       "\n",
       "quartile                        2                        3  \n",
       "4         0.0710 (0.0655, 0.0775)  0.0765 (0.0706, 0.0818)  \n",
       "3         0.0711 (0.0658, 0.0774)  0.0765 (0.0704, 0.0817)  \n",
       "5         0.0718 (0.0661, 0.0786)  0.0776 (0.0716, 0.0829)  \n",
       "6         0.0780 (0.0724, 0.0839)  0.0822 (0.0762, 0.0879)  \n",
       "12        0.0743 (0.0688, 0.0807)  0.0792 (0.0730, 0.0846)  \n",
       "11        0.0721 (0.0666, 0.0785)  0.0770 (0.0711, 0.0824)  \n",
       "13        0.0744 (0.0687, 0.0811)  0.0790 (0.0732, 0.0847)  \n",
       "14        0.0700 (0.0650, 0.0757)  0.0746 (0.0687, 0.0801)  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_repetition = clean_df_briers(df_brier_model_cis[df_brier_model_cis['strat_col'] == 'rr_1'])\n",
    "# Take the 'quartile' column and give each unique value its own column. Use the `formatted_brier` column as the values.\n",
    "df_repetition = df_repetition.pivot(index=['model', 'model_base', 'ctx_length'], columns='quartile', values='formatted_brier').reset_index().sort_values(['model_base', 'ctx_length'])\n",
    "\n",
    "# Limit to first / last for clarity\n",
    "df_model_latex = df_repetition[\n",
    "    (\n",
    "        (df_repetition['model_base'].isin(['mamba', 'hyena']) & df_repetition['ctx_length'].isin([1024, 16384]))\n",
    "        | (df_repetition['model_base'].isin(['gpt2', 'llama']) & df_repetition['ctx_length'].isin([512, 4096]))\n",
    "    )\n",
    "]\n",
    "df_model_latex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>quartile</th>\n",
       "      <th>model</th>\n",
       "      <th>model_base</th>\n",
       "      <th>ctx_length</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gpt2-base-512--clmbr_train-tokens-total_nonPAD...</td>\n",
       "      <td>gpt2</td>\n",
       "      <td>512</td>\n",
       "      <td>0.0645 (0.0603, 0.0691)</td>\n",
       "      <td>0.0705 (0.0658, 0.0751)</td>\n",
       "      <td>0.0745 (0.0691, 0.0785)</td>\n",
       "      <td>0.0692 (0.0629, 0.0772)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gpt2-base-4096--clmbr_train-tokens-total_nonPA...</td>\n",
       "      <td>gpt2</td>\n",
       "      <td>4096</td>\n",
       "      <td>0.0671 (0.0629, 0.0721)</td>\n",
       "      <td>0.0720 (0.0673, 0.0765)</td>\n",
       "      <td>0.0736 (0.0680, 0.0776)</td>\n",
       "      <td>0.0685 (0.0624, 0.0764)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>hyena-large-1024--clmbr_train-tokens-total_non...</td>\n",
       "      <td>hyena</td>\n",
       "      <td>1024</td>\n",
       "      <td>0.0670 (0.0628, 0.0718)</td>\n",
       "      <td>0.0706 (0.0658, 0.0753)</td>\n",
       "      <td>0.0730 (0.0673, 0.0768)</td>\n",
       "      <td>0.0703 (0.0635, 0.0790)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>hyena-large-16384--clmbr_train-tokens-total_no...</td>\n",
       "      <td>hyena</td>\n",
       "      <td>16384</td>\n",
       "      <td>0.0759 (0.0713, 0.0807)</td>\n",
       "      <td>0.0815 (0.0768, 0.0862)</td>\n",
       "      <td>0.0792 (0.0733, 0.0830)</td>\n",
       "      <td>0.0728 (0.0674, 0.0808)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>llama-base-512--clmbr_train-tokens-total_nonPA...</td>\n",
       "      <td>llama</td>\n",
       "      <td>512</td>\n",
       "      <td>0.0666 (0.0623, 0.0715)</td>\n",
       "      <td>0.0728 (0.0682, 0.0771)</td>\n",
       "      <td>0.0758 (0.0700, 0.0799)</td>\n",
       "      <td>0.0733 (0.0670, 0.0819)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>llama-base-4096--clmbr_train-tokens-total_nonP...</td>\n",
       "      <td>llama</td>\n",
       "      <td>4096</td>\n",
       "      <td>0.0651 (0.0608, 0.0698)</td>\n",
       "      <td>0.0715 (0.0669, 0.0759)</td>\n",
       "      <td>0.0738 (0.0682, 0.0779)</td>\n",
       "      <td>0.0700 (0.0639, 0.0785)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>mamba-tiny-1024--clmbr_train-tokens-total_nonP...</td>\n",
       "      <td>mamba</td>\n",
       "      <td>1024</td>\n",
       "      <td>0.0676 (0.0633, 0.0724)</td>\n",
       "      <td>0.0742 (0.0696, 0.0790)</td>\n",
       "      <td>0.0772 (0.0719, 0.0811)</td>\n",
       "      <td>0.0726 (0.0662, 0.0811)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>mamba-tiny-16384--clmbr_train-tokens-total_non...</td>\n",
       "      <td>mamba</td>\n",
       "      <td>16384</td>\n",
       "      <td>0.0633 (0.0592, 0.0680)</td>\n",
       "      <td>0.0689 (0.0643, 0.0735)</td>\n",
       "      <td>0.0718 (0.0665, 0.0758)</td>\n",
       "      <td>0.0681 (0.0628, 0.0756)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "quartile                                              model model_base  \\\n",
       "4         gpt2-base-512--clmbr_train-tokens-total_nonPAD...       gpt2   \n",
       "3         gpt2-base-4096--clmbr_train-tokens-total_nonPA...       gpt2   \n",
       "5         hyena-large-1024--clmbr_train-tokens-total_non...      hyena   \n",
       "6         hyena-large-16384--clmbr_train-tokens-total_no...      hyena   \n",
       "12        llama-base-512--clmbr_train-tokens-total_nonPA...      llama   \n",
       "11        llama-base-4096--clmbr_train-tokens-total_nonP...      llama   \n",
       "13        mamba-tiny-1024--clmbr_train-tokens-total_nonP...      mamba   \n",
       "14        mamba-tiny-16384--clmbr_train-tokens-total_non...      mamba   \n",
       "\n",
       "quartile  ctx_length                        0                        1  \\\n",
       "4                512  0.0645 (0.0603, 0.0691)  0.0705 (0.0658, 0.0751)   \n",
       "3               4096  0.0671 (0.0629, 0.0721)  0.0720 (0.0673, 0.0765)   \n",
       "5               1024  0.0670 (0.0628, 0.0718)  0.0706 (0.0658, 0.0753)   \n",
       "6              16384  0.0759 (0.0713, 0.0807)  0.0815 (0.0768, 0.0862)   \n",
       "12               512  0.0666 (0.0623, 0.0715)  0.0728 (0.0682, 0.0771)   \n",
       "11              4096  0.0651 (0.0608, 0.0698)  0.0715 (0.0669, 0.0759)   \n",
       "13              1024  0.0676 (0.0633, 0.0724)  0.0742 (0.0696, 0.0790)   \n",
       "14             16384  0.0633 (0.0592, 0.0680)  0.0689 (0.0643, 0.0735)   \n",
       "\n",
       "quartile                        2                        3  \n",
       "4         0.0745 (0.0691, 0.0785)  0.0692 (0.0629, 0.0772)  \n",
       "3         0.0736 (0.0680, 0.0776)  0.0685 (0.0624, 0.0764)  \n",
       "5         0.0730 (0.0673, 0.0768)  0.0703 (0.0635, 0.0790)  \n",
       "6         0.0792 (0.0733, 0.0830)  0.0728 (0.0674, 0.0808)  \n",
       "12        0.0758 (0.0700, 0.0799)  0.0733 (0.0670, 0.0819)  \n",
       "11        0.0738 (0.0682, 0.0779)  0.0700 (0.0639, 0.0785)  \n",
       "13        0.0772 (0.0719, 0.0811)  0.0726 (0.0662, 0.0811)  \n",
       "14        0.0718 (0.0665, 0.0758)  0.0681 (0.0628, 0.0756)  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_repetition = clean_df_briers(df_brier_model_cis[df_brier_model_cis['strat_col'] == 'n_events'])\n",
    "# Take the 'quartile' column and give each unique value its own column. Use the `formatted_brier` column as the values.\n",
    "df_repetition = df_repetition.pivot(index=['model', 'model_base', 'ctx_length'], columns='quartile', values='formatted_brier').reset_index().sort_values(['model_base', 'ctx_length'])\n",
    "\n",
    "# Limit to first / last for clarity\n",
    "df_model_latex = df_repetition[\n",
    "    (\n",
    "        (df_repetition['model_base'].isin(['mamba', 'hyena']) & df_repetition['ctx_length'].isin([1024, 16384]))\n",
    "        | (df_repetition['model_base'].isin(['gpt2', 'llama']) & df_repetition['ctx_length'].isin([512, 4096]))\n",
    "    )\n",
    "]\n",
    "df_model_latex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LaTeX Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lllrllll}\n",
      "\\toprule\n",
      "model & model_name & model_base & ctx_length & 0 & 1 & 2 & 3 \\\\\n",
      "\\midrule\n",
      "gpt2-base-512--clmbr_train-tokens-total_nonPAD-ckpt_val=2000000000-persist_chunk:last_embed:last & gpt2-base-512 & gpt2 & 512 & 0.0645 (0.0603, 0.0691) & 0.0705 (0.0658, 0.0751) & 0.0745 (0.0691, 0.0785) & 0.0692 (0.0629, 0.0772) \\\\\n",
      "gpt2-base-4096--clmbr_train-tokens-total_nonPAD-ckpt_val=2000000000-persist_chunk:last_embed:last & gpt2-base-4096 & gpt2 & 4096 & 0.0671 (0.0629, 0.0721) & 0.0720 (0.0673, 0.0765) & 0.0736 (0.0680, 0.0776) & 0.0685 (0.0624, 0.0764) \\\\\n",
      "hyena-large-1024--clmbr_train-tokens-total_nonPAD-ckpt_val=2000000000-persist_chunk:last_embed:last & hyena-large-1024 & hyena & 1024 & 0.0670 (0.0628, 0.0718) & 0.0706 (0.0658, 0.0753) & 0.0730 (0.0673, 0.0768) & 0.0703 (0.0635, 0.0790) \\\\\n",
      "hyena-large-16384--clmbr_train-tokens-total_nonPAD-ckpt_val=2000000000-persist_chunk:last_embed:last & hyena-large-16384 & hyena & 16384 & 0.0759 (0.0713, 0.0807) & 0.0815 (0.0768, 0.0862) & 0.0792 (0.0733, 0.0830) & 0.0728 (0.0674, 0.0808) \\\\\n",
      "llama-base-512--clmbr_train-tokens-total_nonPAD-ckpt_val=2000000000-persist_chunk:last_embed:last & llama-base-512 & llama & 512 & 0.0666 (0.0623, 0.0715) & 0.0728 (0.0682, 0.0771) & 0.0758 (0.0700, 0.0799) & 0.0733 (0.0670, 0.0819) \\\\\n",
      "llama-base-4096--clmbr_train-tokens-total_nonPAD-ckpt_val=2000000000-persist_chunk:last_embed:last & llama-base-4096 & llama & 4096 & 0.0651 (0.0608, 0.0698) & 0.0715 (0.0669, 0.0759) & 0.0738 (0.0682, 0.0779) & 0.0700 (0.0639, 0.0785) \\\\\n",
      "mamba-tiny-1024--clmbr_train-tokens-total_nonPAD-ckpt_val=2000000000-persist_chunk:last_embed:last & mamba-tiny-1024 & mamba & 1024 & 0.0676 (0.0633, 0.0724) & 0.0742 (0.0696, 0.0790) & 0.0772 (0.0719, 0.0811) & 0.0726 (0.0662, 0.0811) \\\\\n",
      "mamba-tiny-16384--clmbr_train-tokens-total_nonPAD-ckpt_val=2000000000-persist_chunk:last_embed:last & mamba-tiny-16384 & mamba & 16384 & 0.0633 (0.0592, 0.0680) & 0.0689 (0.0643, 0.0735) & 0.0718 (0.0665, 0.0758) & 0.0681 (0.0628, 0.0756) \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Model-level delta CIs for LaTeX\n",
    "latex: str = clean_df_briers(df_model_latex)\n",
    "print(latex.to_latex(index=False, escape=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Win Rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>task</th>\n",
       "      <th>strat</th>\n",
       "      <th>strat_col</th>\n",
       "      <th>quartile</th>\n",
       "      <th>win_rate_true</th>\n",
       "      <th>win_rate_ci_mean</th>\n",
       "      <th>win_rate_ci_025</th>\n",
       "      <th>win_rate_ci_500</th>\n",
       "      <th>win_rate_ci_975</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>clmbr</td>\n",
       "      <td>all</td>\n",
       "      <td>inter_event_times</td>\n",
       "      <td>std</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>clmbr</td>\n",
       "      <td>all</td>\n",
       "      <td>n_gram_count</td>\n",
       "      <td>rr_1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>clmbr</td>\n",
       "      <td>all</td>\n",
       "      <td>timeline_lengths</td>\n",
       "      <td>n_events</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>clmbr</td>\n",
       "      <td>all</td>\n",
       "      <td>inter_event_times</td>\n",
       "      <td>std</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>clmbr</td>\n",
       "      <td>all</td>\n",
       "      <td>n_gram_count</td>\n",
       "      <td>rr_1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>mamba-tiny-16384--clmbr_train-tokens-total_non...</td>\n",
       "      <td>all</td>\n",
       "      <td>n_gram_count</td>\n",
       "      <td>rr_1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.756143</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.858929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>mamba-tiny-16384--clmbr_train-tokens-total_non...</td>\n",
       "      <td>all</td>\n",
       "      <td>timeline_lengths</td>\n",
       "      <td>n_events</td>\n",
       "      <td>2</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.783500</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.928571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>mamba-tiny-16384--clmbr_train-tokens-total_non...</td>\n",
       "      <td>all</td>\n",
       "      <td>inter_event_times</td>\n",
       "      <td>std</td>\n",
       "      <td>3</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.713500</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>mamba-tiny-16384--clmbr_train-tokens-total_non...</td>\n",
       "      <td>all</td>\n",
       "      <td>n_gram_count</td>\n",
       "      <td>rr_1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.704357</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>mamba-tiny-16384--clmbr_train-tokens-total_non...</td>\n",
       "      <td>all</td>\n",
       "      <td>timeline_lengths</td>\n",
       "      <td>n_events</td>\n",
       "      <td>3</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.684571</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.857143</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>108 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 model task  \\\n",
       "32                                               clmbr  all   \n",
       "68                                               clmbr  all   \n",
       "104                                              clmbr  all   \n",
       "33                                               clmbr  all   \n",
       "69                                               clmbr  all   \n",
       "..                                                 ...  ...   \n",
       "66   mamba-tiny-16384--clmbr_train-tokens-total_non...  all   \n",
       "102  mamba-tiny-16384--clmbr_train-tokens-total_non...  all   \n",
       "31   mamba-tiny-16384--clmbr_train-tokens-total_non...  all   \n",
       "67   mamba-tiny-16384--clmbr_train-tokens-total_non...  all   \n",
       "103  mamba-tiny-16384--clmbr_train-tokens-total_non...  all   \n",
       "\n",
       "                 strat strat_col  quartile  win_rate_true  win_rate_ci_mean  \\\n",
       "32   inter_event_times       std         0       0.000000          0.000000   \n",
       "68        n_gram_count      rr_1         0       0.000000          0.000000   \n",
       "104   timeline_lengths  n_events         0       0.000000          0.000000   \n",
       "33   inter_event_times       std         1       0.000000          0.000000   \n",
       "69        n_gram_count      rr_1         1       0.000000          0.000000   \n",
       "..                 ...       ...       ...            ...               ...   \n",
       "66        n_gram_count      rr_1         2       0.785714          0.756143   \n",
       "102   timeline_lengths  n_events         2       0.857143          0.783500   \n",
       "31   inter_event_times       std         3       0.714286          0.713500   \n",
       "67        n_gram_count      rr_1         3       0.714286          0.704357   \n",
       "103   timeline_lengths  n_events         3       0.785714          0.684571   \n",
       "\n",
       "     win_rate_ci_025  win_rate_ci_500  win_rate_ci_975  \n",
       "32          0.000000         0.000000         0.000000  \n",
       "68          0.000000         0.000000         0.000000  \n",
       "104         0.000000         0.000000         0.000000  \n",
       "33          0.000000         0.000000         0.000000  \n",
       "69          0.000000         0.000000         0.000000  \n",
       "..               ...              ...              ...  \n",
       "66          0.571429         0.785714         0.858929  \n",
       "102         0.642857         0.785714         0.928571  \n",
       "31          0.571429         0.714286         0.857143  \n",
       "67          0.500000         0.714286         0.857143  \n",
       "103         0.500000         0.714286         0.857143  \n",
       "\n",
       "[108 rows x 10 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate model-level win rates between longest and shortest context lengths for each (model, quartile)\n",
    "df_win_rate_cis = []\n",
    "for strat, strat_cols in strats.items():\n",
    "    for strat_col in strat_cols:\n",
    "        for model in valid_models:\n",
    "\n",
    "            # Only keep shortest and longest context lengths for ease of comparison\n",
    "            if model_to_base(model) in ['mamba', 'hyena' ]:\n",
    "                if model_to_ctx(model) not in [1024, 16384]:\n",
    "                    continue\n",
    "            if model_to_base(model) in ['gpt2', 'llama' ]:\n",
    "                if model_to_ctx(model) not in [512, 4096]:\n",
    "                    continue\n",
    "            baseline_model_name: str = model.replace(str(model_to_ctx(model)), str(1024 if model_to_base(model) in ['mamba', 'hyena' ] else 512))\n",
    "\n",
    "            for quartile in range(4):\n",
    "                win_rates = [] # scores for this quartile, averaged across all tasks\n",
    "                true_win_rate = [] # true scores for this quartile, averaged across all tasks\n",
    "                for task in valid_tasks:\n",
    "                    ## NOTE: Comparison is '>' b/c lower Brier is better\n",
    "                    # True win rate\n",
    "                    true_this_model_score = np.array(true_brier_scores_per_quartile[(model, task, strat, strat_col, quartile)]) # each is 1 x 1\n",
    "                    true_baseline_model_score = np.array(true_brier_scores_per_quartile[(baseline_model_name, task, strat, strat_col, quartile)]) # each is 1 x 1\n",
    "                    assert true_baseline_model_score.shape == true_this_model_score.shape\n",
    "                    true_win_rate.append((true_baseline_model_score > true_this_model_score).astype(bool))\n",
    "                    # Bootstrap win rates\n",
    "                    this_model_scores = np.array(brier_scores_per_quartile[(model, task, strat, strat_col, quartile)]) # each is 1 x 1000\n",
    "                    baseline_model_scores = np.array(brier_scores_per_quartile[(\n",
    "                        baseline_model_name, \n",
    "                        task, strat, strat_col, quartile\n",
    "                    )]) # each is 1 x 1000\n",
    "                    assert baseline_model_scores.shape == this_model_scores.shape\n",
    "                    win_rates.append((baseline_model_scores > this_model_scores).astype(bool))\n",
    "                # Win rates\n",
    "                win_rates = np.vstack(win_rates) # 14 x 1000\n",
    "                assert win_rates.shape == (14, 1000), f\"win_rates.shape={win_rates.shape}\"\n",
    "                win_rates = np.mean(win_rates, axis=0)\n",
    "                assert len(true_win_rate) == 14\n",
    "                df_win_rate_cis.append({\n",
    "                    'model' : model,\n",
    "                    'task' : 'all',\n",
    "                    'strat' : strat,\n",
    "                    'strat_col' : strat_col,\n",
    "                    'quartile' : quartile,\n",
    "                    'win_rate_true' : np.mean(true_win_rate),\n",
    "                    'win_rate_ci_mean' : np.mean(win_rates),\n",
    "                    'win_rate_ci_025' : np.percentile(win_rates, 2.5),\n",
    "                    'win_rate_ci_500' : np.percentile(win_rates, 50),\n",
    "                    'win_rate_ci_975' : np.percentile(win_rates, 97.5),\n",
    "                })\n",
    "df_win_rate_cis = pd.DataFrame(df_win_rate_cis).sort_values(['model', 'quartile'])\n",
    "df_win_rate_cis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>quartile</th>\n",
       "      <th>model</th>\n",
       "      <th>model_base</th>\n",
       "      <th>ctx_length</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>clmbr</td>\n",
       "      <td>clmbr</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000 (0.0000, 0.0000)</td>\n",
       "      <td>0.0000 (0.0000, 0.0000)</td>\n",
       "      <td>0.0000 (0.0000, 0.0000)</td>\n",
       "      <td>0.0000 (0.0000, 0.0000)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gpt2-base-512--clmbr_train-tokens-total_nonPAD...</td>\n",
       "      <td>gpt2</td>\n",
       "      <td>512</td>\n",
       "      <td>0.0000 (0.0000, 0.0000)</td>\n",
       "      <td>0.0000 (0.0000, 0.0000)</td>\n",
       "      <td>0.0000 (0.0000, 0.0000)</td>\n",
       "      <td>0.0000 (0.0000, 0.0000)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gpt2-base-4096--clmbr_train-tokens-total_nonPA...</td>\n",
       "      <td>gpt2</td>\n",
       "      <td>4096</td>\n",
       "      <td>0.4286 (0.1429, 0.5018)</td>\n",
       "      <td>0.5000 (0.3571, 0.6429)</td>\n",
       "      <td>0.5714 (0.2143, 0.6429)</td>\n",
       "      <td>0.5000 (0.2857, 0.6429)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hyena-large-1024--clmbr_train-tokens-total_non...</td>\n",
       "      <td>hyena</td>\n",
       "      <td>1024</td>\n",
       "      <td>0.0000 (0.0000, 0.0000)</td>\n",
       "      <td>0.0000 (0.0000, 0.0000)</td>\n",
       "      <td>0.0000 (0.0000, 0.0000)</td>\n",
       "      <td>0.0000 (0.0000, 0.0000)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hyena-large-16384--clmbr_train-tokens-total_no...</td>\n",
       "      <td>hyena</td>\n",
       "      <td>16384</td>\n",
       "      <td>0.0714 (0.0714, 0.2143)</td>\n",
       "      <td>0.1429 (0.0000, 0.2857)</td>\n",
       "      <td>0.0714 (0.0000, 0.2143)</td>\n",
       "      <td>0.1429 (0.0696, 0.2857)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>llama-base-512--clmbr_train-tokens-total_nonPA...</td>\n",
       "      <td>llama</td>\n",
       "      <td>512</td>\n",
       "      <td>0.0000 (0.0000, 0.0000)</td>\n",
       "      <td>0.0000 (0.0000, 0.0000)</td>\n",
       "      <td>0.0000 (0.0000, 0.0000)</td>\n",
       "      <td>0.0000 (0.0000, 0.0000)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>llama-base-4096--clmbr_train-tokens-total_nonP...</td>\n",
       "      <td>llama</td>\n",
       "      <td>4096</td>\n",
       "      <td>0.6429 (0.5000, 0.8571)</td>\n",
       "      <td>0.7857 (0.5000, 0.8571)</td>\n",
       "      <td>0.6429 (0.5000, 0.8571)</td>\n",
       "      <td>0.8571 (0.5714, 0.9286)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>mamba-tiny-1024--clmbr_train-tokens-total_nonP...</td>\n",
       "      <td>mamba</td>\n",
       "      <td>1024</td>\n",
       "      <td>0.0000 (0.0000, 0.0000)</td>\n",
       "      <td>0.0000 (0.0000, 0.0000)</td>\n",
       "      <td>0.0000 (0.0000, 0.0000)</td>\n",
       "      <td>0.0000 (0.0000, 0.0000)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>mamba-tiny-16384--clmbr_train-tokens-total_non...</td>\n",
       "      <td>mamba</td>\n",
       "      <td>16384</td>\n",
       "      <td>0.7857 (0.5714, 0.8571)</td>\n",
       "      <td>0.8571 (0.6429, 0.9286)</td>\n",
       "      <td>0.7857 (0.5714, 0.8589)</td>\n",
       "      <td>0.7143 (0.5000, 0.8571)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "quartile                                              model model_base  \\\n",
       "0                                                     clmbr      clmbr   \n",
       "2         gpt2-base-512--clmbr_train-tokens-total_nonPAD...       gpt2   \n",
       "1         gpt2-base-4096--clmbr_train-tokens-total_nonPA...       gpt2   \n",
       "3         hyena-large-1024--clmbr_train-tokens-total_non...      hyena   \n",
       "4         hyena-large-16384--clmbr_train-tokens-total_no...      hyena   \n",
       "6         llama-base-512--clmbr_train-tokens-total_nonPA...      llama   \n",
       "5         llama-base-4096--clmbr_train-tokens-total_nonP...      llama   \n",
       "7         mamba-tiny-1024--clmbr_train-tokens-total_nonP...      mamba   \n",
       "8         mamba-tiny-16384--clmbr_train-tokens-total_non...      mamba   \n",
       "\n",
       "quartile  ctx_length                        0                        1  \\\n",
       "0                  0  0.0000 (0.0000, 0.0000)  0.0000 (0.0000, 0.0000)   \n",
       "2                512  0.0000 (0.0000, 0.0000)  0.0000 (0.0000, 0.0000)   \n",
       "1               4096  0.4286 (0.1429, 0.5018)  0.5000 (0.3571, 0.6429)   \n",
       "3               1024  0.0000 (0.0000, 0.0000)  0.0000 (0.0000, 0.0000)   \n",
       "4              16384  0.0714 (0.0714, 0.2143)  0.1429 (0.0000, 0.2857)   \n",
       "6                512  0.0000 (0.0000, 0.0000)  0.0000 (0.0000, 0.0000)   \n",
       "5               4096  0.6429 (0.5000, 0.8571)  0.7857 (0.5000, 0.8571)   \n",
       "7               1024  0.0000 (0.0000, 0.0000)  0.0000 (0.0000, 0.0000)   \n",
       "8              16384  0.7857 (0.5714, 0.8571)  0.8571 (0.6429, 0.9286)   \n",
       "\n",
       "quartile                        2                        3  \n",
       "0         0.0000 (0.0000, 0.0000)  0.0000 (0.0000, 0.0000)  \n",
       "2         0.0000 (0.0000, 0.0000)  0.0000 (0.0000, 0.0000)  \n",
       "1         0.5714 (0.2143, 0.6429)  0.5000 (0.2857, 0.6429)  \n",
       "3         0.0000 (0.0000, 0.0000)  0.0000 (0.0000, 0.0000)  \n",
       "4         0.0714 (0.0000, 0.2143)  0.1429 (0.0696, 0.2857)  \n",
       "6         0.0000 (0.0000, 0.0000)  0.0000 (0.0000, 0.0000)  \n",
       "5         0.6429 (0.5000, 0.8571)  0.8571 (0.5714, 0.9286)  \n",
       "7         0.0000 (0.0000, 0.0000)  0.0000 (0.0000, 0.0000)  \n",
       "8         0.7857 (0.5714, 0.8589)  0.7143 (0.5000, 0.8571)  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_repetition = clean_df_briers(df_win_rate_cis[df_win_rate_cis['strat_col'] == 'rr_1'])\n",
    "df_repetition = df_repetition.pivot(index=['model', 'model_base', 'ctx_length'], columns='quartile', values='formatted_win_rate').reset_index().sort_values(['model_base', 'ctx_length'])\n",
    "df_repetition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>quartile</th>\n",
       "      <th>model</th>\n",
       "      <th>model_base</th>\n",
       "      <th>ctx_length</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>clmbr</td>\n",
       "      <td>clmbr</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000 (0.0000, 0.0000)</td>\n",
       "      <td>0.0000 (0.0000, 0.0000)</td>\n",
       "      <td>0.0000 (0.0000, 0.0000)</td>\n",
       "      <td>0.0000 (0.0000, 0.0000)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gpt2-base-512--clmbr_train-tokens-total_nonPAD...</td>\n",
       "      <td>gpt2</td>\n",
       "      <td>512</td>\n",
       "      <td>0.0000 (0.0000, 0.0000)</td>\n",
       "      <td>0.0000 (0.0000, 0.0000)</td>\n",
       "      <td>0.0000 (0.0000, 0.0000)</td>\n",
       "      <td>0.0000 (0.0000, 0.0000)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gpt2-base-4096--clmbr_train-tokens-total_nonPA...</td>\n",
       "      <td>gpt2</td>\n",
       "      <td>4096</td>\n",
       "      <td>0.5000 (0.2857, 0.7143)</td>\n",
       "      <td>0.4286 (0.2857, 0.6429)</td>\n",
       "      <td>0.5714 (0.3571, 0.7857)</td>\n",
       "      <td>0.4286 (0.2143, 0.5714)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hyena-large-1024--clmbr_train-tokens-total_non...</td>\n",
       "      <td>hyena</td>\n",
       "      <td>1024</td>\n",
       "      <td>0.0000 (0.0000, 0.0000)</td>\n",
       "      <td>0.0000 (0.0000, 0.0000)</td>\n",
       "      <td>0.0000 (0.0000, 0.0000)</td>\n",
       "      <td>0.0000 (0.0000, 0.0000)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hyena-large-16384--clmbr_train-tokens-total_no...</td>\n",
       "      <td>hyena</td>\n",
       "      <td>16384</td>\n",
       "      <td>0.1429 (0.0714, 0.3571)</td>\n",
       "      <td>0.1429 (0.0000, 0.3571)</td>\n",
       "      <td>0.0000 (0.0000, 0.2143)</td>\n",
       "      <td>0.1429 (0.0714, 0.2143)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>llama-base-512--clmbr_train-tokens-total_nonPA...</td>\n",
       "      <td>llama</td>\n",
       "      <td>512</td>\n",
       "      <td>0.0000 (0.0000, 0.0000)</td>\n",
       "      <td>0.0000 (0.0000, 0.0000)</td>\n",
       "      <td>0.0000 (0.0000, 0.0000)</td>\n",
       "      <td>0.0000 (0.0000, 0.0000)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>llama-base-4096--clmbr_train-tokens-total_nonP...</td>\n",
       "      <td>llama</td>\n",
       "      <td>4096</td>\n",
       "      <td>0.7143 (0.5000, 0.8571)</td>\n",
       "      <td>0.7143 (0.5000, 0.8571)</td>\n",
       "      <td>0.8571 (0.5714, 0.9286)</td>\n",
       "      <td>0.4286 (0.4286, 0.7857)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>mamba-tiny-1024--clmbr_train-tokens-total_nonP...</td>\n",
       "      <td>mamba</td>\n",
       "      <td>1024</td>\n",
       "      <td>0.0000 (0.0000, 0.0000)</td>\n",
       "      <td>0.0000 (0.0000, 0.0000)</td>\n",
       "      <td>0.0000 (0.0000, 0.0000)</td>\n",
       "      <td>0.0000 (0.0000, 0.0000)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>mamba-tiny-16384--clmbr_train-tokens-total_non...</td>\n",
       "      <td>mamba</td>\n",
       "      <td>16384</td>\n",
       "      <td>0.8571 (0.5696, 0.8571)</td>\n",
       "      <td>0.8571 (0.5714, 0.9286)</td>\n",
       "      <td>0.8571 (0.6429, 0.9286)</td>\n",
       "      <td>0.7143 (0.5714, 0.8571)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "quartile                                              model model_base  \\\n",
       "0                                                     clmbr      clmbr   \n",
       "2         gpt2-base-512--clmbr_train-tokens-total_nonPAD...       gpt2   \n",
       "1         gpt2-base-4096--clmbr_train-tokens-total_nonPA...       gpt2   \n",
       "3         hyena-large-1024--clmbr_train-tokens-total_non...      hyena   \n",
       "4         hyena-large-16384--clmbr_train-tokens-total_no...      hyena   \n",
       "6         llama-base-512--clmbr_train-tokens-total_nonPA...      llama   \n",
       "5         llama-base-4096--clmbr_train-tokens-total_nonP...      llama   \n",
       "7         mamba-tiny-1024--clmbr_train-tokens-total_nonP...      mamba   \n",
       "8         mamba-tiny-16384--clmbr_train-tokens-total_non...      mamba   \n",
       "\n",
       "quartile  ctx_length                        0                        1  \\\n",
       "0                  0  0.0000 (0.0000, 0.0000)  0.0000 (0.0000, 0.0000)   \n",
       "2                512  0.0000 (0.0000, 0.0000)  0.0000 (0.0000, 0.0000)   \n",
       "1               4096  0.5000 (0.2857, 0.7143)  0.4286 (0.2857, 0.6429)   \n",
       "3               1024  0.0000 (0.0000, 0.0000)  0.0000 (0.0000, 0.0000)   \n",
       "4              16384  0.1429 (0.0714, 0.3571)  0.1429 (0.0000, 0.3571)   \n",
       "6                512  0.0000 (0.0000, 0.0000)  0.0000 (0.0000, 0.0000)   \n",
       "5               4096  0.7143 (0.5000, 0.8571)  0.7143 (0.5000, 0.8571)   \n",
       "7               1024  0.0000 (0.0000, 0.0000)  0.0000 (0.0000, 0.0000)   \n",
       "8              16384  0.8571 (0.5696, 0.8571)  0.8571 (0.5714, 0.9286)   \n",
       "\n",
       "quartile                        2                        3  \n",
       "0         0.0000 (0.0000, 0.0000)  0.0000 (0.0000, 0.0000)  \n",
       "2         0.0000 (0.0000, 0.0000)  0.0000 (0.0000, 0.0000)  \n",
       "1         0.5714 (0.3571, 0.7857)  0.4286 (0.2143, 0.5714)  \n",
       "3         0.0000 (0.0000, 0.0000)  0.0000 (0.0000, 0.0000)  \n",
       "4         0.0000 (0.0000, 0.2143)  0.1429 (0.0714, 0.2143)  \n",
       "6         0.0000 (0.0000, 0.0000)  0.0000 (0.0000, 0.0000)  \n",
       "5         0.8571 (0.5714, 0.9286)  0.4286 (0.4286, 0.7857)  \n",
       "7         0.0000 (0.0000, 0.0000)  0.0000 (0.0000, 0.0000)  \n",
       "8         0.8571 (0.6429, 0.9286)  0.7143 (0.5714, 0.8571)  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_irregularity = clean_df_briers(df_win_rate_cis[df_win_rate_cis['strat_col'] == 'std'])\n",
    "df_irregularity = df_irregularity.pivot(index=['model', 'model_base', 'ctx_length'], columns='quartile', values='formatted_win_rate').reset_index().sort_values(['model_base', 'ctx_length'])\n",
    "df_irregularity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>quartile</th>\n",
       "      <th>model</th>\n",
       "      <th>model_base</th>\n",
       "      <th>ctx_length</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>clmbr</td>\n",
       "      <td>clmbr</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000 (0.0000, 0.0000)</td>\n",
       "      <td>0.0000 (0.0000, 0.0000)</td>\n",
       "      <td>0.0000 (0.0000, 0.0000)</td>\n",
       "      <td>0.0000 (0.0000, 0.0000)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gpt2-base-512--clmbr_train-tokens-total_nonPAD...</td>\n",
       "      <td>gpt2</td>\n",
       "      <td>512</td>\n",
       "      <td>0.0000 (0.0000, 0.0000)</td>\n",
       "      <td>0.0000 (0.0000, 0.0000)</td>\n",
       "      <td>0.0000 (0.0000, 0.0000)</td>\n",
       "      <td>0.0000 (0.0000, 0.0000)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gpt2-base-4096--clmbr_train-tokens-total_nonPA...</td>\n",
       "      <td>gpt2</td>\n",
       "      <td>4096</td>\n",
       "      <td>0.3571 (0.2143, 0.5714)</td>\n",
       "      <td>0.3571 (0.2839, 0.6429)</td>\n",
       "      <td>0.3571 (0.3571, 0.7857)</td>\n",
       "      <td>0.5000 (0.2857, 0.7857)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hyena-large-1024--clmbr_train-tokens-total_non...</td>\n",
       "      <td>hyena</td>\n",
       "      <td>1024</td>\n",
       "      <td>0.0000 (0.0000, 0.0000)</td>\n",
       "      <td>0.0000 (0.0000, 0.0000)</td>\n",
       "      <td>0.0000 (0.0000, 0.0000)</td>\n",
       "      <td>0.0000 (0.0000, 0.0000)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hyena-large-16384--clmbr_train-tokens-total_no...</td>\n",
       "      <td>hyena</td>\n",
       "      <td>16384</td>\n",
       "      <td>0.1429 (0.0714, 0.2857)</td>\n",
       "      <td>0.0714 (0.0000, 0.2143)</td>\n",
       "      <td>0.0714 (0.0000, 0.2857)</td>\n",
       "      <td>0.2143 (0.1429, 0.4286)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>llama-base-512--clmbr_train-tokens-total_nonPA...</td>\n",
       "      <td>llama</td>\n",
       "      <td>512</td>\n",
       "      <td>0.0000 (0.0000, 0.0000)</td>\n",
       "      <td>0.0000 (0.0000, 0.0000)</td>\n",
       "      <td>0.0000 (0.0000, 0.0000)</td>\n",
       "      <td>0.0000 (0.0000, 0.0000)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>llama-base-4096--clmbr_train-tokens-total_nonP...</td>\n",
       "      <td>llama</td>\n",
       "      <td>4096</td>\n",
       "      <td>0.7143 (0.5714, 0.8571)</td>\n",
       "      <td>0.7143 (0.5000, 0.7857)</td>\n",
       "      <td>0.7143 (0.5000, 0.8571)</td>\n",
       "      <td>0.7857 (0.5000, 0.8571)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>mamba-tiny-1024--clmbr_train-tokens-total_nonP...</td>\n",
       "      <td>mamba</td>\n",
       "      <td>1024</td>\n",
       "      <td>0.0000 (0.0000, 0.0000)</td>\n",
       "      <td>0.0000 (0.0000, 0.0000)</td>\n",
       "      <td>0.0000 (0.0000, 0.0000)</td>\n",
       "      <td>0.0000 (0.0000, 0.0000)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>mamba-tiny-16384--clmbr_train-tokens-total_non...</td>\n",
       "      <td>mamba</td>\n",
       "      <td>16384</td>\n",
       "      <td>0.7143 (0.5000, 0.8571)</td>\n",
       "      <td>0.8571 (0.6429, 0.9286)</td>\n",
       "      <td>0.8571 (0.6429, 0.9286)</td>\n",
       "      <td>0.7857 (0.5000, 0.8571)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "quartile                                              model model_base  \\\n",
       "0                                                     clmbr      clmbr   \n",
       "2         gpt2-base-512--clmbr_train-tokens-total_nonPAD...       gpt2   \n",
       "1         gpt2-base-4096--clmbr_train-tokens-total_nonPA...       gpt2   \n",
       "3         hyena-large-1024--clmbr_train-tokens-total_non...      hyena   \n",
       "4         hyena-large-16384--clmbr_train-tokens-total_no...      hyena   \n",
       "6         llama-base-512--clmbr_train-tokens-total_nonPA...      llama   \n",
       "5         llama-base-4096--clmbr_train-tokens-total_nonP...      llama   \n",
       "7         mamba-tiny-1024--clmbr_train-tokens-total_nonP...      mamba   \n",
       "8         mamba-tiny-16384--clmbr_train-tokens-total_non...      mamba   \n",
       "\n",
       "quartile  ctx_length                        0                        1  \\\n",
       "0                  0  0.0000 (0.0000, 0.0000)  0.0000 (0.0000, 0.0000)   \n",
       "2                512  0.0000 (0.0000, 0.0000)  0.0000 (0.0000, 0.0000)   \n",
       "1               4096  0.3571 (0.2143, 0.5714)  0.3571 (0.2839, 0.6429)   \n",
       "3               1024  0.0000 (0.0000, 0.0000)  0.0000 (0.0000, 0.0000)   \n",
       "4              16384  0.1429 (0.0714, 0.2857)  0.0714 (0.0000, 0.2143)   \n",
       "6                512  0.0000 (0.0000, 0.0000)  0.0000 (0.0000, 0.0000)   \n",
       "5               4096  0.7143 (0.5714, 0.8571)  0.7143 (0.5000, 0.7857)   \n",
       "7               1024  0.0000 (0.0000, 0.0000)  0.0000 (0.0000, 0.0000)   \n",
       "8              16384  0.7143 (0.5000, 0.8571)  0.8571 (0.6429, 0.9286)   \n",
       "\n",
       "quartile                        2                        3  \n",
       "0         0.0000 (0.0000, 0.0000)  0.0000 (0.0000, 0.0000)  \n",
       "2         0.0000 (0.0000, 0.0000)  0.0000 (0.0000, 0.0000)  \n",
       "1         0.3571 (0.3571, 0.7857)  0.5000 (0.2857, 0.7857)  \n",
       "3         0.0000 (0.0000, 0.0000)  0.0000 (0.0000, 0.0000)  \n",
       "4         0.0714 (0.0000, 0.2857)  0.2143 (0.1429, 0.4286)  \n",
       "6         0.0000 (0.0000, 0.0000)  0.0000 (0.0000, 0.0000)  \n",
       "5         0.7143 (0.5000, 0.8571)  0.7857 (0.5000, 0.8571)  \n",
       "7         0.0000 (0.0000, 0.0000)  0.0000 (0.0000, 0.0000)  \n",
       "8         0.8571 (0.6429, 0.9286)  0.7857 (0.5000, 0.8571)  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_length = clean_df_briers(df_win_rate_cis[df_win_rate_cis['strat_col'] == 'n_events'])\n",
    "df_length = df_length.pivot(index=['model', 'model_base', 'ctx_length'], columns='quartile', values='formatted_win_rate').reset_index().sort_values(['model_base', 'ctx_length'])\n",
    "df_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
