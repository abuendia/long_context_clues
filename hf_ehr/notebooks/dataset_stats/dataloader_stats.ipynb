{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Statistics about Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mwornow/llama_hf_env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "\u001b[32m2024-10-17 20:47:41.184\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mhf_ehr.trainer.loaders\u001b[0m:\u001b[36mload_dataloaders\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1m====> Loading ApproxBatchSampler\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading `seq_length_per_patient.json` from `/share/pi/nigam/mwornow/hf_ehr/cache/tokenizers/clmbr_v8/versions/2024-07-20_05-21-33/datasets/2024-07-20_05-22-12/seq_length_per_patient.json` for split=`train`\n",
      "Loading `seq_length_per_patient.json` from `/share/pi/nigam/mwornow/hf_ehr/cache/tokenizers/clmbr_v8/versions/2024-07-20_05-21-33/datasets/2024-07-21_10-55-32/seq_length_per_patient.json` for split=`val`\n",
      "Loading `seq_length_per_patient.json` from `/share/pi/nigam/mwornow/hf_ehr/cache/tokenizers/clmbr_v8/versions/2024-07-20_05-21-33/datasets/2024-07-21_11-44-30/seq_length_per_patient.json` for split=`test`\n"
     ]
    }
   ],
   "source": [
    "from hf_ehr.utils import load_config_from_path\n",
    "from hf_ehr.data.tokenization import CLMBRTokenizer\n",
    "from hf_ehr.data.datasets import BaseDataset\n",
    "from torch.utils.data import DataLoader\n",
    "from hf_ehr.trainer.loaders import load_datasets, load_dataloaders\n",
    "from omegaconf import OmegaConf\n",
    "import os\n",
    "from hf_ehr.config import PATH_TO_FEMR_EXTRACT_v8\n",
    "from typing import Dict, List\n",
    "from tqdm import tqdm\n",
    "import json\n",
    " \n",
    "# Load config\n",
    "config = load_config_from_path('/share/pi/nigam/suhana/hf_ehr/cache/runs_backup/mamba-tiny-16384--clmbr/ckpts/train-tokens-total_nonPAD-ckpt_val=2000000000-persist.ckpt')\n",
    "OmegaConf.set_struct(config, False)\n",
    "config.data.dataset.name = 'FEMRDataset'\n",
    "config.data.dataset.path_to_femr_extract = PATH_TO_FEMR_EXTRACT_v8\n",
    "\n",
    "# Load dataloader\n",
    "tokenizer = CLMBRTokenizer( config.data.tokenizer.path_to_config )\n",
    "datasets: Dict[str, BaseDataset] = load_datasets(config, tokenizer)\n",
    "dataloaders: Dict[str, DataLoader] = load_dataloaders(config, datasets, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 7/118431 [00:06<18:14:38,  1.80it/s] Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7feaeb356a70>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/mwornow/llama_hf_env/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1477, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/mwornow/llama_hf_env/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1460, in _shutdown_workers\n",
      "    Exception ignored in: if w.is_alive():<function _MultiProcessingDataLoaderIter.__del__ at 0x7feaeb356a70>\n",
      "  File \"/home/mwornow/llama_hf_env/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: Traceback (most recent call last):\n",
      "can only test a child process  File \"/home/mwornow/llama_hf_env/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1477, in __del__\n",
      "    \n",
      "self._shutdown_workers()\n",
      "  File \"/home/mwornow/llama_hf_env/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1460, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/home/mwornow/llama_hf_env/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7feaeb356a70>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/mwornow/llama_hf_env/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1477, in __del__\n",
      "  0%|          | 9/118431 [00:07<20:53:41,  1.57it/s]    self._shutdown_workers()\n",
      "  File \"/home/mwornow/llama_hf_env/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1460, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/home/mwornow/llama_hf_env/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "  0%|          | 11/118431 [00:08<19:00:46,  1.73it/s]aderIter.__del__ at 0x7feaeb356a70>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/mwornow/llama_hf_env/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1477, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/mwornow/llama_hf_env/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1460, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "assert self._parent_pid == os.getpid(), 'can only test a child process'  File \"/home/mwornow/llama_hf_env/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    \n",
      "AssertionError: can only test a child process\n",
      " 50%|████▉     | 59013/118431 [4:55:41<4:57:43,  3.33it/s] \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m      6\u001b[0m     train_seq_lengths: List[\u001b[38;5;28mint\u001b[39m] \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m----> 7\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m tqdm(dataloaders[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m]):\n\u001b[1;32m      8\u001b[0m         lengths \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtokens\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39msum(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      9\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(lengths) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpatient_ids\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[0;32m~/llama_hf_env/lib/python3.10/site-packages/tqdm/std.py:1178\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1175\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[1;32m   1177\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1178\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[1;32m   1179\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[1;32m   1180\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1181\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[0;32m~/llama_hf_env/lib/python3.10/site-packages/torch/utils/data/dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/llama_hf_env/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1327\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1324\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_data(data)\n\u001b[1;32m   1326\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shutdown \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m-> 1327\u001b[0m idx, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1328\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1329\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable:\n\u001b[1;32m   1330\u001b[0m     \u001b[38;5;66;03m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m~/llama_hf_env/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1283\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1281\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m   1282\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_thread\u001b[38;5;241m.\u001b[39mis_alive():\n\u001b[0;32m-> 1283\u001b[0m         success, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_try_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1284\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[1;32m   1285\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m~/llama_hf_env/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1131\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1118\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_try_get_data\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m_utils\u001b[38;5;241m.\u001b[39mMP_STATUS_CHECK_INTERVAL):\n\u001b[1;32m   1119\u001b[0m     \u001b[38;5;66;03m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001b[39;00m\n\u001b[1;32m   1120\u001b[0m     \u001b[38;5;66;03m# This can also be used as inner loop of fetching without timeout, with\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1128\u001b[0m     \u001b[38;5;66;03m# Returns a 2-tuple:\u001b[39;00m\n\u001b[1;32m   1129\u001b[0m     \u001b[38;5;66;03m#   (bool: whether successfully get data, any: data if successful else None)\u001b[39;00m\n\u001b[1;32m   1130\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1131\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_queue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1132\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, data)\n\u001b[1;32m   1133\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1134\u001b[0m         \u001b[38;5;66;03m# At timeout and error, we manually check whether any worker has\u001b[39;00m\n\u001b[1;32m   1135\u001b[0m         \u001b[38;5;66;03m# failed. Note that this is the only mechanism for Windows to detect\u001b[39;00m\n\u001b[1;32m   1136\u001b[0m         \u001b[38;5;66;03m# worker failures.\u001b[39;00m\n",
      "File \u001b[0;32m~/llama_hf_env/lib/python3.10/queue.py:180\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    178\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m remaining \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m:\n\u001b[1;32m    179\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m Empty\n\u001b[0;32m--> 180\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnot_empty\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mremaining\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    181\u001b[0m item \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get()\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnot_full\u001b[38;5;241m.\u001b[39mnotify()\n",
      "File \u001b[0;32m~/llama_hf_env/lib/python3.10/threading.py:324\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    322\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    323\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 324\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    325\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    326\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m waiter\u001b[38;5;241m.\u001b[39macquire(\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Loop through train dataloader, keeping track of all sequence lengths seen\n",
    "if os.path.exists('../cache/train_seq_lengths-mamba-16k.json'):\n",
    "    data = json.load(open('../cache/train_seq_lengths-mamba-16k.json', 'r'))\n",
    "    train_seq_lengths: List[int] = data['train_seq_lengths']\n",
    "else:\n",
    "    train_seq_lengths: List[int] = []\n",
    "    for batch in tqdm(dataloaders['train']):\n",
    "        lengths = batch['tokens']['attention_mask'].sum(dim=1)\n",
    "        assert len(lengths) == len(batch['patient_ids'])\n",
    "        train_seq_lengths.extend(lengths)\n",
    "    train_seq_lengths = [ x.item() for x in train_seq_lengths ]\n",
    "    json.dump({ 'train_seq_lengths' : train_seq_lengths, }, open('../cache/train_seq_lengths-mamba-16k.json', 'w'))\n",
    "    print(\"# of batches:\", len(dataloaders['train']))\n",
    "print(\"# of seqs:\", len(train_seq_lengths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot histogram of sequence lengths\n",
    "from collections import Counter\n",
    "\n",
    "counter = Counter(train_seq_lengths)\n",
    "plt.scatter(list(counter.keys()), list(counter.values()), s=5)\n",
    "plt.yscale('log')\n",
    "plt.xscale('log')\n",
    "plt.title('Seq Lengths v. Frequency from Train Dataloader (log-log plot)')\n",
    "plt.xlabel('Seq Length (# of tokens)')\n",
    "plt.ylabel('# of Occurrences in Train Dataloader')\n",
    "\n",
    "# Show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot CDF of sequence lengths\n",
    "seq_lengths = np.array(list(counter.keys()))\n",
    "occurrences = np.array(list(counter.values()))\n",
    "sorted_indices = np.argsort(seq_lengths)\n",
    "sorted_seq_lengths = seq_lengths[sorted_indices]\n",
    "sorted_occurrences = occurrences[sorted_indices]\n",
    "\n",
    "# CDF is the cumulative sum of the occurrences divided by the total number of sequences\n",
    "cdf = np.cumsum(sorted_occurrences) / np.sum(sorted_occurrences)\n",
    "\n",
    "# Plot CDF\n",
    "plt.scatter(sorted_seq_lengths, cdf, marker='o', linestyle='-', s=5)\n",
    "plt.title('CDF of Sequence Lengths from Train Dataloader')\n",
    "plt.xlabel('Seq Length (# of tokens)')\n",
    "plt.ylabel('Cumulative Proportion of Samples')\n",
    "\n",
    "# Show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Percentiles\n",
    "print_percentiles(pd.Series(train_seq_lengths))\n",
    "print(\"\\n\")\n",
    "print(\"% of sequences >=512\", len([ x for x in train_seq_lengths if x >= 512 ]) / len(train_seq_lengths))\n",
    "print(\"% of sequences >=768\", len([ x for x in train_seq_lengths if x >= 768 ]) / len(train_seq_lengths))\n",
    "print(\"% of sequences >=1024\", len([ x for x in train_seq_lengths if x >= 1024 ]) / len(train_seq_lengths))\n",
    "print(\"% of sequences >=2048\", len([ x for x in train_seq_lengths if x >= 2048 ]) / len(train_seq_lengths))\n",
    "print(\"% of sequences >=4096\", len([ x for x in train_seq_lengths if x >= 4096 ]) / len(train_seq_lengths))\n",
    "print(\"% of sequences >=8192\", len([ x for x in train_seq_lengths if x >= 8192 ]) / len(train_seq_lengths))\n",
    "print(\"% of sequences >=16384\", len([ x for x in train_seq_lengths if x >= 16384 ]) / len(train_seq_lengths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
