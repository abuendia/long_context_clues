# @package _global_

# TODO (@Miguel)

model:
  # Name of model to load
  name: t5
  # Name/path to pass to HF.from_pretrained()
  hf_name: t5-base
  # Kwargs for ModelConfig
  config_kwargs:
    num_layers: 8
    num_heads: 12
    d_model: 512
    d_ff: 2048
    n_positions: 512

data:
  dataloader:
    # Max number of codes to feed into model at once per patient.
    max_length: ${model.config_kwargs.n_positions}

trainer:
  # If true uses bf16 mixed precision (A100 only)
  is_use_bf16: False
  # If true uses fp16 mixed precision
  is_use_fp16: False
  # Limits training to a minimum number of epochs
  optimizer:
    # Learning rate
    lr: 3e-4
    weight_decay: 0.1

  scheduler:
    # Number of local steps (i.e. non-global) from `initial_lr` -> `trainer.optimizer.lr`
    num_warmup_steps: 40_000
    # Number of local steps (i.e. non-global) from `trainer.optimizer.lr` -> `final_lr`
    num_decay_steps: 4_000_000
    initial_lr: 3e-6
    final_lr: 3e-5