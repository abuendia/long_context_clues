main:
  # Training seed.
  seed: 1
  # Where outputs will be saved; If folder exists, then run will be resumed from this directory's `../ckpts/last.ckpt` file
  path_to_output_dir: /share/pi/nigam/mwornow/hf_ehr/cache/runs/${now:%Y-%m-%d_%H-%M-%S}/

hydra:
  run:
    dir: "${main.path_to_output_dir}"

callbacks:
  early_stopping:
    # If we want to min/max the monitored quantity.
    metric_mode: min
    # Number of epochs with no improvement after which training will be stopped.
    patience: 3
  model_checkpointing:
    # Save the top K best models according to val/loss. If -1, then save all models
    save_top_k: 1
    # Save the most recent K models. If -1, then save all models
    save_most_recent_k: 1
    # Save model every N global steps; if NULL, save after every epoch; overwrites previous model
    # useful for resuming training after a crash
    most_recent_every_n_train_steps: 5_000
    # Save model every N global steps; persists permanently
    every_n_train_steps: 10_000

data:
  # Sampling strategy for dataset: "random", "stratified", "skillit"
  sampling_strat: null
  sampling_kwargs: null
  # Min number of tokens required for a patient timeline to be included in the dataset
  min_token_count: 
  dataset:
    # Path to FEMR extract
    path_to_femr_extract: /share/pi/nigam/data/som-rit-phi-starr-prod.starr_omop_cdm5_deid_2023_08_13_extract_v9_lite
    is_debug: False
  dataloader:
    # # Batch size to be used.  [note: exclusive with `approx_batch_sampler`]
    # batch_size: 4
    # Max tokens in batch to allow  [note: exclusive with `batch_size`]
    approx_batch_sampler:
      max_tokens: 4_096
      bucket_size: 100
      is_random_shuffle_across_buckets: True
      is_random_shuffle_within_buckets: True
    # Number of data loader workers to use.
    n_workers: 10
    # Max number of codes to feed into model at once per patient.
    max_length: 1024
    # If TRUE, then truncate patient timelines at random locations, rather than always doing right-hand side truncation.
    is_truncation_random: True
  tokenizer:
    # Path to tokenizer
    # v9:
    path_to_code_2_int: /share/pi/nigam/mwornow/hf_ehr/cache/tokenizer_v9_lite/code_2_int.json
    path_to_code_2_count: /share/pi/nigam/mwornow/hf_ehr/cache/tokenizer_v9_lite/code_2_count.json
    # v8:
    # path_to_code_2_int: /share/pi/nigam/mwornow/hf_ehr/cache/tokenizer_v8/code_2_int.json
    # path_to_code_2_count: /share/pi/nigam/mwornow/hf_ehr/cache/tokenizer_v8/code_2_count.json
    # Min number of times a code must occur in our FEMR dataset to be included in our tokenizer -- all other codes are dropped from timelines
    min_code_count: null

trainer:
  # Accumulated gradients runs K small batches of size `data.dataloader.batch_size` before doing a backwards pass.
  accumulate_grad_batches: 4
  # Value for gradient clipping
  gradient_clip_value: 3
  # Whether to clip the gradients based on their 'norm' or 'value'
  gradient_clip_algorithm: norm
  # List of devices to run on
  devices: 0, 1, 2, 3
  # Supports: dp, ddp, ddp2, fsdp, deepspeed
  distributed_backend: ddp
  # If true uses bf16 mixed precision (A100 only)
  is_use_bf16: False
  # If true uses fp16 mixed precision
  is_use_fp16: True
  # Limits training to a minimum number of epochs
  min_epochs: 1
  # Limits training to a max number number of epochs
  max_epochs: 1_000
  # Limits training to `N` batches if `int`, or `N%` of batches if `float`
  limit_train_batches: null
  # Limits val to `N` batches if `int`, or `N%` of batches if `float`
  limit_val_batches: null
  # How often we check the validation set within an epoch - `int` is every N batches and `float` is a fraction of the training dataset
  val_check_interval: 0.35
  # OPTIMIZER
  optimizer:
    # Learning rate
    lr: 8e-4
  # SCHEDULER
  scheduler:
    # Number of local steps (i.e. non-global) from `initial_lr` -> `trainer.optimizer.lr`
    num_warmup_steps: 20_000
    # Number of local steps (i.e. non-global) from `trainer.optimizer.lr` -> `final_lr`
    num_decay_steps: 10_000_000
    initial_lr: 3e-6
    final_lr: 3e-5

logging:
  wandb:
    # If true, then turn ON wandb logging
    is_wandb: True
    # Run name
    name: null
  mlflow:
    # If true, then turn ON mlflow logging
    is_mlflow: False
    # Run name
    name: null
  # If TRUE, then calculate + log grad norm over all params (slows down training)
  is_log_grad_norm: False
  # Log every N steps
  log_every_n_steps: 1