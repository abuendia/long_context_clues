[rank: 0] Global seed set to 1
2023-11-27 09:59:15.798 | INFO     | __main__:main:68 - {'main': {'seed': 1, 'path_to_output_dir': '/share/pi/nigam/mwornow/hf_ehr/cache/runs/hyena-8k-v8/'}, 'callbacks': {'early_stopping': {'metric_mode': 'min', 'patience': 3}, 'model_checkpointing': {'save_top_k': 5, 'save_most_recent_k': 1, 'most_recent_every_n_train_steps': 1000, 'every_n_train_steps': 10000}}, 'data': {'dataset': {'path_to_femr_extract': '/share/pi/nigam/data/som-rit-phi-starr-prod.starr_omop_cdm5_deid_2023_02_08_extract_v8_no_notes'}, 'dataloader': {'batch_size': 4, 'n_workers': 10, 'max_length': 8192, 'is_truncation_random': True}, 'tokenizer': {'path_to_code_2_int': '/share/pi/nigam/mwornow/hf_ehr/cache/tokenizer_v8/code_2_int.json', 'path_to_code_2_count': '/share/pi/nigam/mwornow/hf_ehr/cache/tokenizer_v8/code_2_count.json', 'min_code_count': 10}}, 'trainer': {'accumulate_grad_batches': 16, 'gradient_clip_value': 3, 'gradient_clip_algorithm': 'norm', 'devices': [0], 'distributed_backend': 'ddp', 'is_use_bf16': False, 'is_use_fp16': True, 'min_epochs': 1, 'max_epochs': 1, 'limit_train_batches': 1, 'limit_val_batches': 1, 'val_check_interval': 0.1, 'optimizer': {'lr': 0.0003, 'weight_decay': 0.1}, 'scheduler': {'num_warmup_steps': 40000, 'num_decay_steps': 4000000, 'initial_lr': 3e-06, 'final_lr': 3e-05}}, 'logging': {'wandb': {'is_wandb': True, 'name': 'hyena-8k-v8'}, 'is_log_grad_norm': False, 'log_every_n_steps': 1}, 'model': {'name': 'hyena', 'hf_name': 'LongSafari/hyenadna-large-1m-seqlen-hf', 'config_kwargs': {'n_layer': 4, 'max_seq_len': 8192, 'd_model': 256, 'd_inner': 1024}}}
{'main': {'seed': 1, 'path_to_output_dir': '/share/pi/nigam/mwornow/hf_ehr/cache/runs/hyena-8k-v8/'}, 'callbacks': {'early_stopping': {'metric_mode': 'min', 'patience': 3}, 'model_checkpointing': {'save_top_k': 5, 'save_most_recent_k': 1, 'most_recent_every_n_train_steps': 1000, 'every_n_train_steps': 10000}}, 'data': {'dataset': {'path_to_femr_extract': '/share/pi/nigam/data/som-rit-phi-starr-prod.starr_omop_cdm5_deid_2023_02_08_extract_v8_no_notes'}, 'dataloader': {'batch_size': 4, 'n_workers': 10, 'max_length': 8192, 'is_truncation_random': True}, 'tokenizer': {'path_to_code_2_int': '/share/pi/nigam/mwornow/hf_ehr/cache/tokenizer_v8/code_2_int.json', 'path_to_code_2_count': '/share/pi/nigam/mwornow/hf_ehr/cache/tokenizer_v8/code_2_count.json', 'min_code_count': 10}}, 'trainer': {'accumulate_grad_batches': 16, 'gradient_clip_value': 3, 'gradient_clip_algorithm': 'norm', 'devices': [0], 'distributed_backend': 'ddp', 'is_use_bf16': False, 'is_use_fp16': True, 'min_epochs': 1, 'max_epochs': 1, 'limit_train_batches': 1, 'limit_val_batches': 1, 'val_check_interval': 0.1, 'optimizer': {'lr': 0.0003, 'weight_decay': 0.1}, 'scheduler': {'num_warmup_steps': 40000, 'num_decay_steps': 4000000, 'initial_lr': 3e-06, 'final_lr': 3e-05}}, 'logging': {'wandb': {'is_wandb': True, 'name': 'hyena-8k-v8'}, 'is_log_grad_norm': False, 'log_every_n_steps': 1}, 'model': {'name': 'hyena', 'hf_name': 'LongSafari/hyenadna-large-1m-seqlen-hf', 'config_kwargs': {'n_layer': 4, 'max_seq_len': 8192, 'd_model': 256, 'd_inner': 1024}}}
[2023-11-27 09:59:15,882][wandb.util][WARNING] - Unable to read the token file at /var/run/secrets/kubernetes.io/serviceaccount/token due to permission error ([Errno 13] Permission denied: '/var/run/secrets/kubernetes.io/serviceaccount/token').The current user id is 1300068. Consider changing the securityContext to run the container as the current user.
wandb: WARNING Unable to read the token file at /var/run/secrets/kubernetes.io/serviceaccount/token due to permission error ([Errno 13] Permission denied: '/var/run/secrets/kubernetes.io/serviceaccount/token').The current user id is 1300068. Consider changing the securityContext to run the container as the current user.
wandb: Currently logged in as: miking98. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.16.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.11
wandb: Run data is saved locally in /share/pi/nigam/mwornow/hf_ehr/cache/runs/hyena-8k-v8/logs/wandb/run-20231127_095920-k7q5a9g0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run hyena-8k-v8
wandb: ⭐️ View project at https://wandb.ai/miking98/hf_ehr
wandb: 🚀 View run at https://wandb.ai/miking98/hf_ehr/runs/k7q5a9g0
2023-11-27 09:59:31.639 | INFO     | __main__:main:103 - ========================== Starting main ==========================
2023-11-27 09:59:31.640 | INFO     | __main__:main:104 - >>>> Training from SCRATCH | Saving to: `/share/pi/nigam/mwornow/hf_ehr/cache/runs/hyena-8k-v8/` <<<<
2023-11-27 09:59:31.640 | INFO     | __main__:main:107 - Loading tokenizer: `/share/pi/nigam/mwornow/hf_ehr/cache/tokenizer_v8/code_2_int.json`
2023-11-27 09:59:40.443 | INFO     | __main__:main:111 - Vocab size: `179060`
2023-11-27 09:59:40.444 | INFO     | __main__:main:114 - Loading model: `hyena`
2023-11-27 09:59:57.693 | INFO     | __main__:main:125 - Parameter count of model = 95117056
2023-11-27 09:59:57.693 | INFO     | __main__:main:128 - Loading FEMR datasets...
2023-11-27 10:00:18.486 | INFO     | __main__:main:132 - Loading FEMR dataloaders...
/share/pi/nigam/mwornow/tools/miniconda3/envs/hf_env/lib/python3.10/site-packages/lightning_fabric/connector.py:554: UserWarning: 16 is supported for historical reasons but its usage is discouraged. Please set your precision to 16-mixed instead!
  rank_zero_warn(
/share/pi/nigam/mwornow/tools/miniconda3/envs/hf_env/lib/python3.10/site-packages/lightning_fabric/plugins/environments/slurm.py:168: PossibleUserWarning: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python3 run.py +models=hyena +data=v8 data.dataloader.batch ...
  rank_zero_warn(
Using 16bit Automatic Mixed Precision (AMP)
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer(limit_train_batches=1)` was configured so 1 batch per epoch will be used.
`Trainer(limit_val_batches=1)` was configured so 1 batch will be used.
/share/pi/nigam/mwornow/tools/miniconda3/envs/hf_env/lib/python3.10/site-packages/lightning_fabric/plugins/environments/slurm.py:168: PossibleUserWarning: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python3 run.py +models=hyena +data=v8 data.dataloader.batch ...
  rank_zero_warn(
[rank: 0] Global seed set to 1
Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/1
[W socket.cpp:426] [c10d] The server socket cannot be initialized on [::]:33455 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:601] [c10d] The client socket cannot be initialized to connect to [localhost]:33455 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:601] [c10d] The client socket cannot be initialized to connect to [localhost]:33455 (errno: 97 - Address family not supported by protocol).
[2023-11-27 10:00:20,769][torch.distributed.distributed_c10d][INFO] - Added key: store_based_barrier_key:1 to store for rank: 0
[2023-11-27 10:00:20,770][torch.distributed.distributed_c10d][INFO] - Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 1 nodes.
----------------------------------------------------------------------------------------------------
distributed_backend=nccl
All distributed processes registered. Starting with 1 processes
----------------------------------------------------------------------------------------------------

You are using a CUDA device ('NVIDIA A100 80GB PCIe') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

  | Name        | Type          | Params
----------------------------------------------
0 | sum_metrics | ModuleDict    | 0     
1 | model       | HyenaDNAModel | 49.3 M
2 | lm_head     | Linear        | 45.8 M
----------------------------------------------
95.1 M    Trainable params
0         Non-trainable params
95.1 M    Total params
380.468   Total estimated model params size (MB)
Sanity Checking: 0it [00:00, ?it/s]Sanity Checking:   0%|          | 0/1 [00:00<?, ?it/s]Sanity Checking DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Sanity Checking DataLoader 0: 100%|██████████| 1/1 [00:02<00:00,  2.77s/it]                                                                           Training: 0it [00:00, ?it/s]Training:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/1 [00:00<?, ?it/s] /share/pi/nigam/mwornow/tools/miniconda3/envs/hf_env/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:139: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
Epoch 0: 100%|██████████| 1/1 [00:01<00:00,  1.50s/it]Epoch 0: 100%|██████████| 1/1 [00:01<00:00,  1.50s/it, v_num=a9g0, train/loss=12.20]
Validation: 0it [00:00, ?it/s][A
Validation:   0%|          | 0/1 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s][A
Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 78.10it/s][A
                                                                      [AEpoch 0: 100%|██████████| 1/1 [00:02<00:00,  2.69s/it, v_num=a9g0, train/loss=12.20, val/loss=12.20]/share/pi/nigam/mwornow/tools/miniconda3/envs/hf_env/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: The ``compute`` method of metric SumMetric was called before the ``update`` method which may lead to errors, as metric states have not yet been updated.
  warnings.warn(*args, **kwargs)  # noqa: B028
Epoch 0: 100%|██████████| 1/1 [00:17<00:00, 17.08s/it, v_num=a9g0, train/loss=12.20, val/loss=12.20]`Trainer.fit` stopped: `max_epochs=1` reached.
Epoch 0: 100%|██████████| 1/1 [00:17<00:00, 17.08s/it, v_num=a9g0, train/loss=12.20, val/loss=12.20]FIT Profiler Report

----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
|  Action                                                                                                                                                                  	|  Mean duration (s)	|  Num calls      	|  Total time (s) 	|  Percentage %   	|
----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
|  Total                                                                                                                                                                   	|  -              	|  250            	|  682.01         	|  100 %          	|
----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
|  run_training_epoch                                                                                                                                                      	|  17.075         	|  1              	|  17.075         	|  2.5036         	|
|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_validation_end                 	|  3.6978         	|  2              	|  7.3957         	|  1.0844         	|
|  [Callback]ModelCheckpoint{'monitor': 'step', 'mode': 'max', 'every_n_train_steps': 1000, 'every_n_epochs': 0, 'train_time_interval': None}.on_validation_end            	|  3.4929         	|  2              	|  6.9857         	|  1.0243         	|
|  [Strategy]DDPStrategy.validation_step                                                                                                                                   	|  1.3887         	|  2              	|  2.7774         	|  0.40724        	|
|  [_EvaluationLoop].val_next                                                                                                                                              	|  0.27807        	|  4              	|  1.1123         	|  0.16309        	|
|  run_training_batch                                                                                                                                                      	|  0.45138        	|  1              	|  0.45138        	|  0.066185       	|
|  [LightningModule]HyenaLanguageModel.optimizer_step                                                                                                                      	|  0.45105        	|  1              	|  0.45105        	|  0.066135       	|
|  [Strategy]DDPStrategy.backward                                                                                                                                          	|  0.40421        	|  1              	|  0.40421        	|  0.059267       	|
|  [_TrainingEpochLoop].train_dataloader_next                                                                                                                              	|  0.36467        	|  1              	|  0.36467        	|  0.05347        	|
|  [Strategy]DDPStrategy.training_step                                                                                                                                     	|  0.035929       	|  1              	|  0.035929       	|  0.0052681      	|
|  [LightningModule]HyenaLanguageModel.on_save_checkpoint                                                                                                                  	|  0.0027185      	|  2              	|  0.005437       	|  0.0007972      	|
|  [Callback]ModelSummary.on_fit_start                                                                                                                                     	|  0.0030746      	|  1              	|  0.0030746      	|  0.00045081     	|
|  [Callback]TQDMProgressBar.on_train_batch_end                                                                                                                            	|  0.0021858      	|  1              	|  0.0021858      	|  0.0003205      	|
|  [LightningModule]HyenaLanguageModel.on_validation_model_eval                                                                                                            	|  0.0010399      	|  2              	|  0.0020798      	|  0.00030495     	|
|  [Callback]TQDMProgressBar.on_validation_batch_start                                                                                                                     	|  0.0008322      	|  2              	|  0.0016644      	|  0.00024404     	|
|  [Callback]TQDMProgressBar.on_validation_start                                                                                                                           	|  0.00077131     	|  2              	|  0.0015426      	|  0.00022619     	|
|  [Callback]TQDMProgressBar.on_sanity_check_start                                                                                                                         	|  0.0013864      	|  1              	|  0.0013864      	|  0.00020328     	|
|  [LightningModule]HyenaLanguageModel.configure_gradient_clipping                                                                                                         	|  0.0013544      	|  1              	|  0.0013544      	|  0.0001986      	|
|  [Strategy]DDPStrategy.batch_to_device                                                                                                                                   	|  0.00044262     	|  3              	|  0.0013279      	|  0.0001947      	|
|  [Callback]TQDMProgressBar.on_validation_end                                                                                                                             	|  0.00061655     	|  2              	|  0.0012331      	|  0.0001808      	|
|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 10000, 'every_n_epochs': 0, 'train_time_interval': None}.on_validation_end             	|  0.00056003     	|  2              	|  0.0011201      	|  0.00016423     	|
|  [Callback]ModelCheckpoint{'monitor': 'val/loss', 'mode': 'min', 'every_n_train_steps': 1000, 'every_n_epochs': 0, 'train_time_interval': None}.on_validation_end        	|  0.00049095     	|  2              	|  0.00098191     	|  0.00014397     	|
|  [Callback]TQDMProgressBar.on_validation_batch_end                                                                                                                       	|  0.00047271     	|  2              	|  0.00094542     	|  0.00013862     	|
|  [LightningModule]HyenaLanguageModel.transfer_batch_to_device                                                                                                            	|  0.00031227     	|  3              	|  0.00093681     	|  0.00013736     	|
|  [LightningModule]HyenaLanguageModel.on_validation_model_train                                                                                                           	|  0.00043379     	|  2              	|  0.00086758     	|  0.00012721     	|
|  [LightningModule]HyenaLanguageModel.configure_optimizers                                                                                                                	|  0.00072815     	|  1              	|  0.00072815     	|  0.00010677     	|
|  [Callback]ModelCheckpoint{'monitor': 'val/loss', 'mode': 'min', 'every_n_train_steps': 1000, 'every_n_epochs': 0, 'train_time_interval': None}.setup                    	|  0.00053079     	|  1              	|  0.00053079     	|  7.7827e-05     	|
|  [Callback]TQDMProgressBar.on_train_epoch_end                                                                                                                            	|  0.00052331     	|  1              	|  0.00052331     	|  7.6731e-05     	|
|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.setup                             	|  0.00034076     	|  1              	|  0.00034076     	|  4.9964e-05     	|
|  [Callback]TQDMProgressBar.on_train_start                                                                                                                                	|  0.00030565     	|  1              	|  0.00030565     	|  4.4815e-05     	|
|  [Callback]TQDMProgressBar.on_train_epoch_start                                                                                                                          	|  0.00030228     	|  1              	|  0.00030228     	|  4.4322e-05     	|
|  [Callback]TQDMProgressBar.on_train_end                                                                                                                                  	|  0.00028514     	|  1              	|  0.00028514     	|  4.181e-05      	|
|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 10000, 'every_n_epochs': 0, 'train_time_interval': None}.setup                         	|  0.00027902     	|  1              	|  0.00027902     	|  4.0912e-05     	|
|  [Callback]ModelCheckpoint{'monitor': 'step', 'mode': 'max', 'every_n_train_steps': 1000, 'every_n_epochs': 0, 'train_time_interval': None}.setup                        	|  0.0002657      	|  1              	|  0.0002657      	|  3.8959e-05     	|
|  [LightningModule]HyenaLanguageModel.optimizer_zero_grad                                                                                                                 	|  9.1076e-05     	|  1              	|  9.1076e-05     	|  1.3354e-05     	|
|  [Callback]ModelCheckpoint{'monitor': 'val/loss', 'mode': 'min', 'every_n_train_steps': 1000, 'every_n_epochs': 0, 'train_time_interval': None}.on_train_batch_end       	|  3.591e-05      	|  1              	|  3.591e-05      	|  5.2653e-06     	|
|  [Callback]ModelCheckpoint{'monitor': 'val/loss', 'mode': 'min', 'every_n_train_steps': 1000, 'every_n_epochs': 0, 'train_time_interval': None}.on_train_epoch_end       	|  2.8769e-05     	|  1              	|  2.8769e-05     	|  4.2182e-06     	|
|  [LightningModule]HyenaLanguageModel.on_before_batch_transfer                                                                                                            	|  7.4655e-06     	|  3              	|  2.2396e-05     	|  3.2839e-06     	|
|  [LightningModule]HyenaLanguageModel.lr_scheduler_step                                                                                                                   	|  2.1433e-05     	|  1              	|  2.1433e-05     	|  3.1427e-06     	|
|  [Callback]ModelSummary.on_validation_start                                                                                                                              	|  8.5821e-06     	|  2              	|  1.7164e-05     	|  2.5167e-06     	|
|  [Callback]ModelSummary.on_validation_batch_start                                                                                                                        	|  5.0496e-06     	|  2              	|  1.0099e-05     	|  1.4808e-06     	|
|  [Callback]TQDMProgressBar.setup                                                                                                                                         	|  1.0055e-05     	|  1              	|  1.0055e-05     	|  1.4743e-06     	|
|  [Callback]TQDMProgressBar.on_save_checkpoint                                                                                                                            	|  4.6417e-06     	|  2              	|  9.2834e-06     	|  1.3612e-06     	|
|  [Callback]ModelSummary.on_validation_batch_end                                                                                                                          	|  4.5588e-06     	|  2              	|  9.1176e-06     	|  1.3369e-06     	|
|  [Callback]ModelSummary.on_validation_end                                                                                                                                	|  4.1751e-06     	|  2              	|  8.3502e-06     	|  1.2244e-06     	|
|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 10000, 'every_n_epochs': 0, 'train_time_interval': None}.on_train_epoch_end            	|  7.9218e-06     	|  1              	|  7.9218e-06     	|  1.1615e-06     	|
|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_train_batch_end                	|  7.7393e-06     	|  1              	|  7.7393e-06     	|  1.1348e-06     	|
|  [Callback]TQDMProgressBar.on_validation_epoch_end                                                                                                                       	|  3.8408e-06     	|  2              	|  7.6815e-06     	|  1.1263e-06     	|
|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 10000, 'every_n_epochs': 0, 'train_time_interval': None}.on_train_batch_end            	|  7.3649e-06     	|  1              	|  7.3649e-06     	|  1.0799e-06     	|
|  [Strategy]DDPStrategy.on_validation_start                                                                                                                               	|  3.6256e-06     	|  2              	|  7.2513e-06     	|  1.0632e-06     	|
|  [Callback]ModelCheckpoint{'monitor': 'step', 'mode': 'max', 'every_n_train_steps': 1000, 'every_n_epochs': 0, 'train_time_interval': None}.on_train_batch_end           	|  7.0054e-06     	|  1              	|  7.0054e-06     	|  1.0272e-06     	|
|  [LightningModule]HyenaLanguageModel.on_after_batch_transfer                                                                                                             	|  2.2979e-06     	|  3              	|  6.8936e-06     	|  1.0108e-06     	|
|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_train_epoch_end                	|  6.7987e-06     	|  1              	|  6.7987e-06     	|  9.9686e-07     	|
|  [Callback]TQDMProgressBar.on_after_backward                                                                                                                             	|  6.1877e-06     	|  1              	|  6.1877e-06     	|  9.0728e-07     	|
|  [LightningModule]HyenaLanguageModel.configure_callbacks                                                                                                                 	|  6.13e-06       	|  1              	|  6.13e-06       	|  8.9881e-07     	|
|  [Callback]TQDMProgressBar.on_train_batch_start                                                                                                                          	|  5.9474e-06     	|  1              	|  5.9474e-06     	|  8.7205e-07     	|
|  [Callback]TQDMProgressBar.on_before_zero_grad                                                                                                                           	|  5.7314e-06     	|  1              	|  5.7314e-06     	|  8.4037e-07     	|
|  [Callback]TQDMProgressBar.on_fit_end                                                                                                                                    	|  5.6252e-06     	|  1              	|  5.6252e-06     	|  8.248e-07      	|
|  [Callback]ModelCheckpoint{'monitor': 'step', 'mode': 'max', 'every_n_train_steps': 1000, 'every_n_epochs': 0, 'train_time_interval': None}.on_train_epoch_end           	|  5.3607e-06     	|  1              	|  5.3607e-06     	|  7.8602e-07     	|
|  [Callback]TQDMProgressBar.on_sanity_check_end                                                                                                                           	|  5.0683e-06     	|  1              	|  5.0683e-06     	|  7.4314e-07     	|
|  [LightningModule]HyenaLanguageModel.on_validation_batch_end                                                                                                             	|  2.2566e-06     	|  2              	|  4.5132e-06     	|  6.6175e-07     	|
|  [LightningModule]HyenaLanguageModel.on_validation_epoch_end                                                                                                             	|  2.2203e-06     	|  2              	|  4.4405e-06     	|  6.511e-07      	|
|  [Strategy]DDPStrategy.on_validation_end                                                                                                                                 	|  2.1243e-06     	|  2              	|  4.2487e-06     	|  6.2297e-07     	|
|  [Callback]ModelSummary.on_train_epoch_end                                                                                                                               	|  4.2301e-06     	|  1              	|  4.2301e-06     	|  6.2024e-07     	|
|  [Callback]ModelSummary.on_sanity_check_start                                                                                                                            	|  4.1761e-06     	|  1              	|  4.1761e-06     	|  6.1232e-07     	|
|  [Callback]ModelSummary.on_train_batch_end                                                                                                                               	|  3.8389e-06     	|  1              	|  3.8389e-06     	|  5.6288e-07     	|
|  [LightningModule]HyenaLanguageModel.on_before_zero_grad                                                                                                                 	|  3.7737e-06     	|  1              	|  3.7737e-06     	|  5.5332e-07     	|
|  [Callback]TQDMProgressBar.on_before_optimizer_step                                                                                                                      	|  3.7532e-06     	|  1              	|  3.7532e-06     	|  5.5032e-07     	|
|  [Callback]TQDMProgressBar.on_fit_start                                                                                                                                  	|  3.58e-06       	|  1              	|  3.58e-06       	|  5.2492e-07     	|
|  [LightningModule]HyenaLanguageModel.prepare_data                                                                                                                        	|  3.5763e-06     	|  1              	|  3.5763e-06     	|  5.2437e-07     	|
|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 10000, 'every_n_epochs': 0, 'train_time_interval': None}.on_validation_epoch_end       	|  1.7369e-06     	|  2              	|  3.4738e-06     	|  5.0935e-07     	|
|  [Callback]ModelCheckpoint{'monitor': 'val/loss', 'mode': 'min', 'every_n_train_steps': 1000, 'every_n_epochs': 0, 'train_time_interval': None}.on_validation_batch_start	|  1.7202e-06     	|  2              	|  3.4403e-06     	|  5.0444e-07     	|
|  [LightningModule]HyenaLanguageModel.on_train_batch_start                                                                                                                	|  3.4384e-06     	|  1              	|  3.4384e-06     	|  5.0416e-07     	|
|  [LightningModule]HyenaLanguageModel.on_validation_end                                                                                                                   	|  1.6894e-06     	|  2              	|  3.3788e-06     	|  4.9542e-07     	|
|  [Strategy]DDPStrategy.on_train_batch_start                                                                                                                              	|  3.2801e-06     	|  1              	|  3.2801e-06     	|  4.8095e-07     	|
|  [Callback]ModelCheckpoint{'monitor': 'val/loss', 'mode': 'min', 'every_n_train_steps': 1000, 'every_n_epochs': 0, 'train_time_interval': None}.on_fit_start             	|  3.1888e-06     	|  1              	|  3.1888e-06     	|  4.6757e-07     	|
|  [Callback]ModelCheckpoint{'monitor': 'val/loss', 'mode': 'min', 'every_n_train_steps': 1000, 'every_n_epochs': 0, 'train_time_interval': None}.on_save_checkpoint       	|  1.5628e-06     	|  2              	|  3.1255e-06     	|  4.5828e-07     	|
|  [Callback]ModelCheckpoint{'monitor': 'val/loss', 'mode': 'min', 'every_n_train_steps': 1000, 'every_n_epochs': 0, 'train_time_interval': None}.on_validation_batch_end  	|  1.532e-06      	|  2              	|  3.0641e-06     	|  4.4927e-07     	|
|  [Callback]ModelSummary.on_save_checkpoint                                                                                                                               	|  1.5255e-06     	|  2              	|  3.051e-06      	|  4.4736e-07     	|
|  [Callback]ModelCheckpoint{'monitor': 'val/loss', 'mode': 'min', 'every_n_train_steps': 1000, 'every_n_epochs': 0, 'train_time_interval': None}.on_validation_start      	|  1.519e-06      	|  2              	|  3.038e-06      	|  4.4545e-07     	|
|  [LightningModule]HyenaLanguageModel.on_validation_batch_start                                                                                                           	|  1.4352e-06     	|  2              	|  2.8703e-06     	|  4.2087e-07     	|
|  [Callback]TQDMProgressBar.on_validation_epoch_start                                                                                                                     	|  1.411e-06      	|  2              	|  2.8219e-06     	|  4.1376e-07     	|
|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 10000, 'every_n_epochs': 0, 'train_time_interval': None}.on_validation_start           	|  1.4044e-06     	|  2              	|  2.8089e-06     	|  4.1185e-07     	|
|  [Callback]ModelSummary.on_validation_epoch_end                                                                                                                          	|  1.3914e-06     	|  2              	|  2.7828e-06     	|  4.0803e-07     	|
|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_validation_batch_end           	|  1.3784e-06     	|  2              	|  2.7567e-06     	|  4.0421e-07     	|
|  [Callback]ModelCheckpoint{'monitor': 'step', 'mode': 'max', 'every_n_train_steps': 1000, 'every_n_epochs': 0, 'train_time_interval': None}.on_validation_batch_start    	|  1.3253e-06     	|  2              	|  2.6505e-06     	|  3.8864e-07     	|
|  [Callback]TQDMProgressBar.on_before_backward                                                                                                                            	|  2.6263e-06     	|  1              	|  2.6263e-06     	|  3.8509e-07     	|
|  [Callback]ModelSummary.on_train_start                                                                                                                                   	|  2.5611e-06     	|  1              	|  2.5611e-06     	|  3.7553e-07     	|
|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_validation_batch_start         	|  1.2619e-06     	|  2              	|  2.5239e-06     	|  3.7007e-07     	|
|  [Callback]ModelSummary.on_train_end                                                                                                                                     	|  2.4959e-06     	|  1              	|  2.4959e-06     	|  3.6597e-07     	|
|  [Callback]ModelCheckpoint{'monitor': 'val/loss', 'mode': 'min', 'every_n_train_steps': 1000, 'every_n_epochs': 0, 'train_time_interval': None}.on_validation_epoch_end  	|  1.2415e-06     	|  2              	|  2.4829e-06     	|  3.6406e-07     	|
|  [Callback]ModelCheckpoint{'monitor': 'step', 'mode': 'max', 'every_n_train_steps': 1000, 'every_n_epochs': 0, 'train_time_interval': None}.on_validation_start          	|  1.2405e-06     	|  2              	|  2.481e-06      	|  3.6378e-07     	|
|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_validation_start               	|  1.2135e-06     	|  2              	|  2.427e-06      	|  3.5586e-07     	|
|  [Callback]ModelSummary.on_train_epoch_start                                                                                                                             	|  2.4196e-06     	|  1              	|  2.4196e-06     	|  3.5477e-07     	|
|  [LightningModule]HyenaLanguageModel.on_validation_start                                                                                                                 	|  1.1902e-06     	|  2              	|  2.3805e-06     	|  3.4904e-07     	|
|  [Callback]ModelCheckpoint{'monitor': 'val/loss', 'mode': 'min', 'every_n_train_steps': 1000, 'every_n_epochs': 0, 'train_time_interval': None}.on_train_start           	|  2.3711e-06     	|  1              	|  2.3711e-06     	|  3.4767e-07     	|
|  [Callback]ModelCheckpoint{'monitor': 'step', 'mode': 'max', 'every_n_train_steps': 1000, 'every_n_epochs': 0, 'train_time_interval': None}.on_validation_epoch_end      	|  1.1707e-06     	|  2              	|  2.3413e-06     	|  3.433e-07      	|
|  [Callback]ModelCheckpoint{'monitor': 'step', 'mode': 'max', 'every_n_train_steps': 1000, 'every_n_epochs': 0, 'train_time_interval': None}.on_validation_batch_end      	|  1.1642e-06     	|  2              	|  2.3283e-06     	|  3.4139e-07     	|
|  [Callback]ModelSummary.setup                                                                                                                                            	|  2.2855e-06     	|  1              	|  2.2855e-06     	|  3.3511e-07     	|
|  [Callback]ModelCheckpoint{'monitor': 'val/loss', 'mode': 'min', 'every_n_train_steps': 1000, 'every_n_epochs': 0, 'train_time_interval': None}.on_validation_epoch_start	|  1.1288e-06     	|  2              	|  2.2575e-06     	|  3.3101e-07     	|
|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 10000, 'every_n_epochs': 0, 'train_time_interval': None}.on_validation_batch_end       	|  1.1194e-06     	|  2              	|  2.2389e-06     	|  3.2828e-07     	|
|  [LightningModule]HyenaLanguageModel.on_fit_start                                                                                                                        	|  2.2184e-06     	|  1              	|  2.2184e-06     	|  3.2528e-07     	|
|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 10000, 'every_n_epochs': 0, 'train_time_interval': None}.on_validation_batch_start     	|  1.1092e-06     	|  2              	|  2.2184e-06     	|  3.2528e-07     	|
|  [Callback]ModelCheckpoint{'monitor': 'step', 'mode': 'max', 'every_n_train_steps': 1000, 'every_n_epochs': 0, 'train_time_interval': None}.on_validation_epoch_start    	|  1.085e-06      	|  2              	|  2.17e-06       	|  3.1818e-07     	|
|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_validation_epoch_end           	|  1.0654e-06     	|  2              	|  2.1309e-06     	|  3.1244e-07     	|
|  [Callback]ModelCheckpoint{'monitor': 'step', 'mode': 'max', 'every_n_train_steps': 1000, 'every_n_epochs': 0, 'train_time_interval': None}.on_save_checkpoint           	|  1.0645e-06     	|  2              	|  2.129e-06      	|  3.1217e-07     	|
|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 10000, 'every_n_epochs': 0, 'train_time_interval': None}.on_validation_epoch_start     	|  1.0617e-06     	|  2              	|  2.1234e-06     	|  3.1135e-07     	|
|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_validation_epoch_start         	|  1.0356e-06     	|  2              	|  2.0713e-06     	|  3.037e-07      	|
|  [LightningModule]HyenaLanguageModel.setup                                                                                                                               	|  1.9912e-06     	|  1              	|  1.9912e-06     	|  2.9196e-07     	|
|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 10000, 'every_n_epochs': 0, 'train_time_interval': None}.on_save_checkpoint            	|  9.9186e-07     	|  2              	|  1.9837e-06     	|  2.9086e-07     	|
|  [Callback]ModelSummary.on_validation_epoch_start                                                                                                                        	|  9.8627e-07     	|  2              	|  1.9725e-06     	|  2.8923e-07     	|
|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_save_checkpoint                	|  9.8255e-07     	|  2              	|  1.9651e-06     	|  2.8813e-07     	|
|  [LightningModule]HyenaLanguageModel.configure_sharded_model                                                                                                             	|  1.8682e-06     	|  1              	|  1.8682e-06     	|  2.7393e-07     	|
|  [Callback]TQDMProgressBar.teardown                                                                                                                                      	|  1.8422e-06     	|  1              	|  1.8422e-06     	|  2.7011e-07     	|
|  [LightningModule]HyenaLanguageModel.on_after_backward                                                                                                                   	|  1.8328e-06     	|  1              	|  1.8328e-06     	|  2.6874e-07     	|
|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_before_zero_grad               	|  1.8142e-06     	|  1              	|  1.8142e-06     	|  2.6601e-07     	|
|  [Callback]ModelSummary.on_before_backward                                                                                                                               	|  1.8124e-06     	|  1              	|  1.8124e-06     	|  2.6574e-07     	|
|  [LightningModule]HyenaLanguageModel.on_validation_epoch_start                                                                                                           	|  8.9779e-07     	|  2              	|  1.7956e-06     	|  2.6328e-07     	|
|  [Callback]ModelSummary.on_train_batch_start                                                                                                                             	|  1.7788e-06     	|  1              	|  1.7788e-06     	|  2.6082e-07     	|
|  [Callback]ModelCheckpoint{'monitor': 'val/loss', 'mode': 'min', 'every_n_train_steps': 1000, 'every_n_epochs': 0, 'train_time_interval': None}.on_sanity_check_start    	|  1.7118e-06     	|  1              	|  1.7118e-06     	|  2.5099e-07     	|
|  [LightningModule]HyenaLanguageModel.on_fit_end                                                                                                                          	|  1.6578e-06     	|  1              	|  1.6578e-06     	|  2.4307e-07     	|
|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_train_start                    	|  1.5702e-06     	|  1              	|  1.5702e-06     	|  2.3023e-07     	|
|  [Callback]ModelSummary.on_sanity_check_end                                                                                                                              	|  1.5385e-06     	|  1              	|  1.5385e-06     	|  2.2559e-07     	|
|  [Callback]ModelCheckpoint{'monitor': 'step', 'mode': 'max', 'every_n_train_steps': 1000, 'every_n_epochs': 0, 'train_time_interval': None}.on_before_optimizer_step     	|  1.5292e-06     	|  1              	|  1.5292e-06     	|  2.2422e-07     	|
|  [Callback]ModelCheckpoint{'monitor': 'step', 'mode': 'max', 'every_n_train_steps': 1000, 'every_n_epochs': 0, 'train_time_interval': None}.on_train_batch_start         	|  1.5125e-06     	|  1              	|  1.5125e-06     	|  2.2177e-07     	|
|  [LightningModule]HyenaLanguageModel.on_train_epoch_end                                                                                                                  	|  1.5069e-06     	|  1              	|  1.5069e-06     	|  2.2095e-07     	|
|  [Callback]ModelSummary.on_before_zero_grad                                                                                                                              	|  1.4659e-06     	|  1              	|  1.4659e-06     	|  2.1494e-07     	|
|  [Callback]ModelCheckpoint{'monitor': 'val/loss', 'mode': 'min', 'every_n_train_steps': 1000, 'every_n_epochs': 0, 'train_time_interval': None}.on_train_epoch_start     	|  1.4473e-06     	|  1              	|  1.4473e-06     	|  2.1221e-07     	|
|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 10000, 'every_n_epochs': 0, 'train_time_interval': None}.on_train_epoch_start          	|  1.4324e-06     	|  1              	|  1.4324e-06     	|  2.1002e-07     	|
|  [LightningModule]HyenaLanguageModel.on_train_end                                                                                                                        	|  1.4268e-06     	|  1              	|  1.4268e-06     	|  2.092e-07      	|
|  [LightningModule]HyenaLanguageModel.on_train_batch_end                                                                                                                  	|  1.4212e-06     	|  1              	|  1.4212e-06     	|  2.0838e-07     	|
|  [LightningModule]HyenaLanguageModel.on_train_start                                                                                                                      	|  1.3988e-06     	|  1              	|  1.3988e-06     	|  2.0511e-07     	|
|  [Callback]ModelSummary.on_fit_end                                                                                                                                       	|  1.397e-06      	|  1              	|  1.397e-06      	|  2.0483e-07     	|
|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 10000, 'every_n_epochs': 0, 'train_time_interval': None}.on_fit_start                  	|  1.3839e-06     	|  1              	|  1.3839e-06     	|  2.0292e-07     	|
|  [Callback]ModelSummary.on_after_backward                                                                                                                                	|  1.3839e-06     	|  1              	|  1.3839e-06     	|  2.0292e-07     	|
|  [LightningModule]HyenaLanguageModel.on_before_optimizer_step                                                                                                            	|  1.3728e-06     	|  1              	|  1.3728e-06     	|  2.0128e-07     	|
|  [Callback]ModelSummary.teardown                                                                                                                                         	|  1.3653e-06     	|  1              	|  1.3653e-06     	|  2.0019e-07     	|
|  [Callback]ModelCheckpoint{'monitor': 'val/loss', 'mode': 'min', 'every_n_train_steps': 1000, 'every_n_epochs': 0, 'train_time_interval': None}.on_train_batch_start     	|  1.356e-06      	|  1              	|  1.356e-06      	|  1.9883e-07     	|
|  [Callback]ModelSummary.on_before_optimizer_step                                                                                                                         	|  1.356e-06      	|  1              	|  1.356e-06      	|  1.9883e-07     	|
|  [Callback]ModelCheckpoint{'monitor': 'step', 'mode': 'max', 'every_n_train_steps': 1000, 'every_n_epochs': 0, 'train_time_interval': None}.on_train_start               	|  1.3448e-06     	|  1              	|  1.3448e-06     	|  1.9719e-07     	|
|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_sanity_check_start             	|  1.3392e-06     	|  1              	|  1.3392e-06     	|  1.9637e-07     	|
|  [LightningModule]HyenaLanguageModel.teardown                                                                                                                            	|  1.3281e-06     	|  1              	|  1.3281e-06     	|  1.9473e-07     	|
|  [Callback]ModelCheckpoint{'monitor': 'val/loss', 'mode': 'min', 'every_n_train_steps': 1000, 'every_n_epochs': 0, 'train_time_interval': None}.on_before_optimizer_step 	|  1.3225e-06     	|  1              	|  1.3225e-06     	|  1.9391e-07     	|
|  [Callback]ModelCheckpoint{'monitor': 'val/loss', 'mode': 'min', 'every_n_train_steps': 1000, 'every_n_epochs': 0, 'train_time_interval': None}.teardown                 	|  1.3113e-06     	|  1              	|  1.3113e-06     	|  1.9227e-07     	|
|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_fit_end                        	|  1.3001e-06     	|  1              	|  1.3001e-06     	|  1.9063e-07     	|
|  [Callback]ModelCheckpoint{'monitor': 'val/loss', 'mode': 'min', 'every_n_train_steps': 1000, 'every_n_epochs': 0, 'train_time_interval': None}.on_train_end             	|  1.2927e-06     	|  1              	|  1.2927e-06     	|  1.8954e-07     	|
|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 10000, 'every_n_epochs': 0, 'train_time_interval': None}.on_train_start                	|  1.2908e-06     	|  1              	|  1.2908e-06     	|  1.8927e-07     	|
|  [Callback]ModelCheckpoint{'monitor': 'val/loss', 'mode': 'min', 'every_n_train_steps': 1000, 'every_n_epochs': 0, 'train_time_interval': None}.on_before_backward       	|  1.2834e-06     	|  1              	|  1.2834e-06     	|  1.8817e-07     	|
|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_train_epoch_start              	|  1.2778e-06     	|  1              	|  1.2778e-06     	|  1.8735e-07     	|
|  [Strategy]DDPStrategy.on_train_start                                                                                                                                    	|  1.2722e-06     	|  1              	|  1.2722e-06     	|  1.8654e-07     	|
|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 10000, 'every_n_epochs': 0, 'train_time_interval': None}.on_before_optimizer_step      	|  1.2405e-06     	|  1              	|  1.2405e-06     	|  1.8189e-07     	|
|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 10000, 'every_n_epochs': 0, 'train_time_interval': None}.on_train_batch_start          	|  1.2368e-06     	|  1              	|  1.2368e-06     	|  1.8135e-07     	|
|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 10000, 'every_n_epochs': 0, 'train_time_interval': None}.teardown                      	|  1.2331e-06     	|  1              	|  1.2331e-06     	|  1.808e-07      	|
|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_fit_start                      	|  1.2312e-06     	|  1              	|  1.2312e-06     	|  1.8053e-07     	|
|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_sanity_check_end               	|  1.2238e-06     	|  1              	|  1.2238e-06     	|  1.7943e-07     	|
|  [Callback]ModelCheckpoint{'monitor': 'step', 'mode': 'max', 'every_n_train_steps': 1000, 'every_n_epochs': 0, 'train_time_interval': None}.teardown                     	|  1.2163e-06     	|  1              	|  1.2163e-06     	|  1.7834e-07     	|
|  [Callback]ModelCheckpoint{'monitor': 'val/loss', 'mode': 'min', 'every_n_train_steps': 1000, 'every_n_epochs': 0, 'train_time_interval': None}.on_after_backward        	|  1.2051e-06     	|  1              	|  1.2051e-06     	|  1.767e-07      	|
|  [Callback]ModelCheckpoint{'monitor': 'step', 'mode': 'max', 'every_n_train_steps': 1000, 'every_n_epochs': 0, 'train_time_interval': None}.on_before_zero_grad          	|  1.1995e-06     	|  1              	|  1.1995e-06     	|  1.7588e-07     	|
|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.teardown                          	|  1.1958e-06     	|  1              	|  1.1958e-06     	|  1.7534e-07     	|
|  [Callback]ModelCheckpoint{'monitor': 'val/loss', 'mode': 'min', 'every_n_train_steps': 1000, 'every_n_epochs': 0, 'train_time_interval': None}.on_before_zero_grad      	|  1.194e-06      	|  1              	|  1.194e-06      	|  1.7506e-07     	|
|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_before_backward                	|  1.1921e-06     	|  1              	|  1.1921e-06     	|  1.7479e-07     	|
|  [LightningModule]HyenaLanguageModel.on_train_epoch_start                                                                                                                	|  1.1735e-06     	|  1              	|  1.1735e-06     	|  1.7206e-07     	|
|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 10000, 'every_n_epochs': 0, 'train_time_interval': None}.on_sanity_check_start         	|  1.1697e-06     	|  1              	|  1.1697e-06     	|  1.7151e-07     	|
|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_before_optimizer_step          	|  1.1697e-06     	|  1              	|  1.1697e-06     	|  1.7151e-07     	|
|  [Callback]ModelCheckpoint{'monitor': 'val/loss', 'mode': 'min', 'every_n_train_steps': 1000, 'every_n_epochs': 0, 'train_time_interval': None}.on_fit_end               	|  1.166e-06      	|  1              	|  1.166e-06      	|  1.7097e-07     	|
|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 10000, 'every_n_epochs': 0, 'train_time_interval': None}.on_before_zero_grad           	|  1.1623e-06     	|  1              	|  1.1623e-06     	|  1.7042e-07     	|
|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_after_backward                 	|  1.1604e-06     	|  1              	|  1.1604e-06     	|  1.7015e-07     	|
|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_train_end                      	|  1.1586e-06     	|  1              	|  1.1586e-06     	|  1.6988e-07     	|
|  [Callback]ModelCheckpoint{'monitor': 'val/loss', 'mode': 'min', 'every_n_train_steps': 1000, 'every_n_epochs': 0, 'train_time_interval': None}.on_sanity_check_end      	|  1.1548e-06     	|  1              	|  1.1548e-06     	|  1.6933e-07     	|
|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_train_batch_start              	|  1.1511e-06     	|  1              	|  1.1511e-06     	|  1.6878e-07     	|
|  [Callback]ModelCheckpoint{'monitor': 'step', 'mode': 'max', 'every_n_train_steps': 1000, 'every_n_epochs': 0, 'train_time_interval': None}.on_sanity_check_end          	|  1.1399e-06     	|  1              	|  1.1399e-06     	|  1.6714e-07     	|
|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 10000, 'every_n_epochs': 0, 'train_time_interval': None}.on_after_backward             	|  1.1399e-06     	|  1              	|  1.1399e-06     	|  1.6714e-07     	|
|  [Callback]ModelCheckpoint{'monitor': 'step', 'mode': 'max', 'every_n_train_steps': 1000, 'every_n_epochs': 0, 'train_time_interval': None}.on_after_backward            	|  1.1288e-06     	|  1              	|  1.1288e-06     	|  1.6551e-07     	|
|  [Callback]ModelCheckpoint{'monitor': 'step', 'mode': 'max', 'every_n_train_steps': 1000, 'every_n_epochs': 0, 'train_time_interval': None}.on_sanity_check_start        	|  1.1194e-06     	|  1              	|  1.1194e-06     	|  1.6414e-07     	|
|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 10000, 'every_n_epochs': 0, 'train_time_interval': None}.on_fit_end                    	|  1.1045e-06     	|  1              	|  1.1045e-06     	|  1.6196e-07     	|
|  [Callback]ModelCheckpoint{'monitor': 'step', 'mode': 'max', 'every_n_train_steps': 1000, 'every_n_epochs': 0, 'train_time_interval': None}.on_fit_start                 	|  1.1027e-06     	|  1              	|  1.1027e-06     	|  1.6168e-07     	|
|  [Callback]ModelCheckpoint{'monitor': 'step', 'mode': 'max', 'every_n_train_steps': 1000, 'every_n_epochs': 0, 'train_time_interval': None}.on_train_epoch_start         	|  1.0934e-06     	|  1              	|  1.0934e-06     	|  1.6032e-07     	|
|  [LightningModule]HyenaLanguageModel.on_before_backward                                                                                                                  	|  1.0878e-06     	|  1              	|  1.0878e-06     	|  1.595e-07      	|
|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 10000, 'every_n_epochs': 0, 'train_time_interval': None}.on_before_backward            	|  1.058e-06      	|  1              	|  1.058e-06      	|  1.5513e-07     	|
|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 10000, 'every_n_epochs': 0, 'train_time_interval': None}.on_train_end                  	|  1.0561e-06     	|  1              	|  1.0561e-06     	|  1.5485e-07     	|
|  [Callback]ModelCheckpoint{'monitor': 'step', 'mode': 'max', 'every_n_train_steps': 1000, 'every_n_epochs': 0, 'train_time_interval': None}.on_train_end                 	|  1.0449e-06     	|  1              	|  1.0449e-06     	|  1.5322e-07     	|
|  [Callback]ModelCheckpoint{'monitor': 'step', 'mode': 'max', 'every_n_train_steps': 1000, 'every_n_epochs': 0, 'train_time_interval': None}.on_before_backward           	|  1.0282e-06     	|  1              	|  1.0282e-06     	|  1.5076e-07     	|
|  [Callback]ModelCheckpoint{'monitor': 'step', 'mode': 'max', 'every_n_train_steps': 1000, 'every_n_epochs': 0, 'train_time_interval': None}.on_fit_end                   	|  1.0114e-06     	|  1              	|  1.0114e-06     	|  1.483e-07      	|
|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 10000, 'every_n_epochs': 0, 'train_time_interval': None}.on_sanity_check_end           	|  9.9652e-07     	|  1              	|  9.9652e-07     	|  1.4611e-07     	|
|  [Strategy]DDPStrategy.on_train_end                                                                                                                                      	|  7.7486e-07     	|  1              	|  7.7486e-07     	|  1.1361e-07     	|
----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                     epoch ▁▁
wandb:                  optim/lr ▁
wandb:      train/examples/batch ▁
wandb:      train/examples/total ▁
wandb:                train/loss ▁
wandb:                 train/ppl ▁
wandb:    train/tokens/batch_PAD ▁
wandb:    train/tokens/batch_all ▁
wandb: train/tokens/batch_nonPAD ▁
wandb:    train/tokens/total_PAD ▁
wandb:    train/tokens/total_all ▁
wandb: train/tokens/total_nonPAD ▁
wandb:       trainer/global_step ▁▁
wandb:                  val/loss ▁
wandb:                   val/ppl ▁
wandb: 
wandb: Run summary:
wandb:                     epoch 0
wandb:                  optim/lr 0.0
wandb:      train/examples/batch 4.0
wandb:      train/examples/total 4.0
wandb:                 train/ppl 100.0
wandb:    train/tokens/batch_PAD 1428.0
wandb:    train/tokens/batch_all 2540.0
wandb: train/tokens/batch_nonPAD 1112.0
wandb:    train/tokens/total_PAD 1428.0
wandb:    train/tokens/total_all 2540.0
wandb: train/tokens/total_nonPAD 1112.0
wandb:       trainer/global_step 0
wandb:                   val/ppl 100.0
wandb: 
wandb: 🚀 View run hyena-8k-v8 at: https://wandb.ai/miking98/hf_ehr/runs/k7q5a9g0
wandb: ️⚡ View job at https://wandb.ai/miking98/hf_ehr/jobs/QXJ0aWZhY3RDb2xsZWN0aW9uOjEwNTM5MDI5Mg==/version_details/v54
wandb: Synced 7 W&B file(s), 0 media file(s), 3 artifact file(s) and 1 other file(s)
wandb: Find logs at: /share/pi/nigam/mwornow/hf_ehr/cache/runs/hyena-8k-v8/logs/wandb/run-20231127_095920-k7q5a9g0/logs

