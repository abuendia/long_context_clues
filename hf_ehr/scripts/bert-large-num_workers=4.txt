/home/hf_ehr/hf_env/lib/python3.10/site-packages/transformers/utils/hub.py:124: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
====> Done loading imports:  8.106431245803833 s
[rank: 0] Seed set to 1
2024-04-04 09:29:41.080 | INFO     | __main__:main:119 - {'main': {'seed': 1, 'path_to_output_dir': '/share/pi/nigam/mwornow/hf_ehr/cache/runs/bert-large/'}, 'callbacks': {'early_stopping': {'metric_mode': 'min', 'patience': 3}, 'model_checkpointing': {'save_top_k': 1, 'save_most_recent_k': 1, 'most_recent_every_n_train_steps': 5000, 'every_n_train_steps': 10000}}, 'data': {'dataset': {'path_to_femr_extract': '/home/hf_ehr/som-rit-phi-starr-prod.starr_omop_cdm5_deid_2023_08_13_extract_v9_lite'}, 'dataloader': {'batch_size': 2, 'n_workers': 4, 'max_length': '${model.config_kwargs.max_position_embeddings}', 'is_truncation_random': True}, 'tokenizer': {'path_to_code_2_int': '/home/hf_ehr/code_2_int.json', 'path_to_code_2_count': '/home/hf_ehr/code_2_count.json', 'min_code_count': None}}, 'trainer': {'accumulate_grad_batches': 8, 'gradient_clip_value': 3, 'gradient_clip_algorithm': 'norm', 'devices': [0, 1, 2, 3], 'distributed_backend': 'ddp', 'is_use_bf16': False, 'is_use_fp16': True, 'min_epochs': 1, 'max_epochs': 1000, 'limit_train_batches': None, 'limit_val_batches': None, 'val_check_interval': 0.25, 'optimizer': {'lr': 0.0001}, 'scheduler': {'num_warmup_steps': 50000, 'num_decay_steps': 4000000, 'initial_lr': 3e-06, 'final_lr': 3e-05}, 'mlm_mask_pct': 0.15}, 'logging': {'wandb': {'is_wandb': True, 'name': 'bert-large'}, 'mlflow': {'is_mlflow': False, 'name': None}, 'is_log_grad_norm': False, 'log_every_n_steps': 1}, 'model': {'name': 'bert', 'hf_name': 'bert-base-uncased', 'config_kwargs': {'num_hidden_layers': 24, 'num_attention_heads': 16, 'hidden_size': 1024, 'max_position_embeddings': 1024}}}
Loading data from local-scratch: `/home/hf_ehr/`.
{'main': {'seed': 1, 'path_to_output_dir': '/share/pi/nigam/mwornow/hf_ehr/cache/runs/bert-large/'}, 'callbacks': {'early_stopping': {'metric_mode': 'min', 'patience': 3}, 'model_checkpointing': {'save_top_k': 1, 'save_most_recent_k': 1, 'most_recent_every_n_train_steps': 5000, 'every_n_train_steps': 10000}}, 'data': {'dataset': {'path_to_femr_extract': '/home/hf_ehr/som-rit-phi-starr-prod.starr_omop_cdm5_deid_2023_08_13_extract_v9_lite'}, 'dataloader': {'batch_size': 2, 'n_workers': 4, 'max_length': '${model.config_kwargs.max_position_embeddings}', 'is_truncation_random': True}, 'tokenizer': {'path_to_code_2_int': '/home/hf_ehr/code_2_int.json', 'path_to_code_2_count': '/home/hf_ehr/code_2_count.json', 'min_code_count': None}}, 'trainer': {'accumulate_grad_batches': 8, 'gradient_clip_value': 3, 'gradient_clip_algorithm': 'norm', 'devices': [0, 1, 2, 3], 'distributed_backend': 'ddp', 'is_use_bf16': False, 'is_use_fp16': True, 'min_epochs': 1, 'max_epochs': 1000, 'limit_train_batches': None, 'limit_val_batches': None, 'val_check_interval': 0.25, 'optimizer': {'lr': 0.0001}, 'scheduler': {'num_warmup_steps': 50000, 'num_decay_steps': 4000000, 'initial_lr': 3e-06, 'final_lr': 3e-05}, 'mlm_mask_pct': 0.15}, 'logging': {'wandb': {'is_wandb': True, 'name': 'bert-large'}, 'mlflow': {'is_mlflow': False, 'name': None}, 'is_log_grad_norm': False, 'log_every_n_steps': 1}, 'model': {'name': 'bert', 'hf_name': 'bert-base-uncased', 'config_kwargs': {'num_hidden_layers': 24, 'num_attention_heads': 16, 'hidden_size': 1024, 'max_position_embeddings': 1024}}}
[2024-04-04 09:29:42,577][wandb.util][WARNING] - Unable to read the token file at /var/run/secrets/kubernetes.io/serviceaccount/token due to permission error ([Errno 13] Permission denied: '/var/run/secrets/kubernetes.io/serviceaccount/token').The current user id is 1300068. Consider changing the securityContext to run the container as the current user.
wandb: WARNING Unable to read the token file at /var/run/secrets/kubernetes.io/serviceaccount/token due to permission error ([Errno 13] Permission denied: '/var/run/secrets/kubernetes.io/serviceaccount/token').The current user id is 1300068. Consider changing the securityContext to run the container as the current user.
wandb: Currently logged in as: miking98 (ehr-fm). Use `wandb login --relogin` to force relogin
wandb: wandb version 0.16.6 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.11
wandb: Run data is saved locally in /share/pi/nigam/mwornow/wandb_cache/wandb/run-20240404_092944-a5u0xdvf
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run valiant-mountain-103
wandb: ⭐️ View project at https://wandb.ai/ehr-fm/hf_ehr-hf_ehr_scripts
wandb: 🚀 View run at https://wandb.ai/ehr-fm/hf_ehr-hf_ehr_scripts/runs/a5u0xdvf
2024-04-04 09:29:50.473 | INFO     | __main__:main:194 - ========================== Starting main ==========================
2024-04-04 09:29:50.474 | INFO     | __main__:main:195 - >>>> Training from SCRATCH | Saving to: `/share/pi/nigam/mwornow/hf_ehr/cache/runs/bert-large/` <<<<
2024-04-04 09:29:50.474 | INFO     | __main__:main:198 - Loading tokenizer: `/home/hf_ehr/code_2_int.json`
2024-04-04 09:29:50.681 | INFO     | __main__:main:202 - Vocab size: `167238`
2024-04-04 09:29:50.682 | INFO     | __main__:main:205 - Loading model: `bert`
[2024-04-04 09:29:50,692][torch.distributed.nn.jit.instantiator][INFO] - Created a temporary directory at /tmp/tmp3740pi09
[2024-04-04 09:29:50,693][torch.distributed.nn.jit.instantiator][INFO] - Writing /tmp/tmp3740pi09/_remote_module_non_scriptable.py
2024-04-04 09:30:00.340 | INFO     | __main__:main:219 - Parameter count of model = 595511296
2024-04-04 09:30:00.342 | INFO     | __main__:main:222 - Loading FEMR datasets...
2024-04-04 09:30:24.171 | INFO     | __main__:main:226 - Loading FEMR dataloaders...
/home/hf_ehr/hf_env/lib/python3.10/site-packages/lightning/fabric/connector.py:563: `precision=16` is supported for historical reasons but its usage is discouraged. Please set your precision to 16-mixed instead!
/home/hf_ehr/hf_env/lib/python3.10/site-packages/lightning/fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python3 ../run.py +models=bert data.dataloader.batch_size=2 ...
Using 16bit Automatic Mixed Precision (AMP)
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
/home/hf_ehr/hf_env/lib/python3.10/site-packages/lightning/fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python3 ../run.py +models=bert data.dataloader.batch_size=2 ...
[rank: 0] Seed set to 1
Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4
[W socket.cpp:426] [c10d] The server socket cannot be initialized on [::]:37627 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:601] [c10d] The client socket cannot be initialized to connect to [localhost]:37627 (errno: 97 - Address family not supported by protocol).
/home/hf_ehr/hf_env/lib/python3.10/site-packages/transformers/utils/hub.py:124: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
/home/hf_ehr/hf_env/lib/python3.10/site-packages/transformers/utils/hub.py:124: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
/home/hf_ehr/hf_env/lib/python3.10/site-packages/transformers/utils/hub.py:124: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
====> Done loading imports:  3.5392916202545166 s
[rank: 3] Seed set to 1
====> Done loading imports:  3.5715346336364746 s
====> Done loading imports:  3.648056745529175 s
2024-04-04 09:30:30.367 | INFO     | __main__:main:119 - {'main': {'seed': 1, 'path_to_output_dir': '/share/pi/nigam/mwornow/hf_ehr/cache/runs/bert-large/'}, 'callbacks': {'early_stopping': {'metric_mode': 'min', 'patience': 3}, 'model_checkpointing': {'save_top_k': 1, 'save_most_recent_k': 1, 'most_recent_every_n_train_steps': 5000, 'every_n_train_steps': 10000}}, 'data': {'dataset': {'path_to_femr_extract': '/home/hf_ehr/som-rit-phi-starr-prod.starr_omop_cdm5_deid_2023_08_13_extract_v9_lite'}, 'dataloader': {'batch_size': 2, 'n_workers': 4, 'max_length': '${model.config_kwargs.max_position_embeddings}', 'is_truncation_random': True}, 'tokenizer': {'path_to_code_2_int': '/home/hf_ehr/code_2_int.json', 'path_to_code_2_count': '/home/hf_ehr/code_2_count.json', 'min_code_count': None}}, 'trainer': {'accumulate_grad_batches': 8, 'gradient_clip_value': 3, 'gradient_clip_algorithm': 'norm', 'devices': [0, 1, 2, 3], 'distributed_backend': 'ddp', 'is_use_bf16': False, 'is_use_fp16': True, 'min_epochs': 1, 'max_epochs': 1000, 'limit_train_batches': None, 'limit_val_batches': None, 'val_check_interval': 0.25, 'optimizer': {'lr': 0.0001}, 'scheduler': {'num_warmup_steps': 50000, 'num_decay_steps': 4000000, 'initial_lr': 3e-06, 'final_lr': 3e-05}, 'mlm_mask_pct': 0.15}, 'logging': {'wandb': {'is_wandb': True, 'name': 'bert-large'}, 'mlflow': {'is_mlflow': False, 'name': None}, 'is_log_grad_norm': False, 'log_every_n_steps': 1}, 'model': {'name': 'bert', 'hf_name': 'bert-base-uncased', 'config_kwargs': {'num_hidden_layers': 24, 'num_attention_heads': 16, 'hidden_size': 1024, 'max_position_embeddings': 1024}}}
[rank: 1] Seed set to 1
[rank: 2] Seed set to 1
2024-04-04 09:30:30.379 | INFO     | __main__:main:119 - {'main': {'seed': 1, 'path_to_output_dir': '/share/pi/nigam/mwornow/hf_ehr/cache/runs/bert-large/'}, 'callbacks': {'early_stopping': {'metric_mode': 'min', 'patience': 3}, 'model_checkpointing': {'save_top_k': 1, 'save_most_recent_k': 1, 'most_recent_every_n_train_steps': 5000, 'every_n_train_steps': 10000}}, 'data': {'dataset': {'path_to_femr_extract': '/home/hf_ehr/som-rit-phi-starr-prod.starr_omop_cdm5_deid_2023_08_13_extract_v9_lite'}, 'dataloader': {'batch_size': 2, 'n_workers': 4, 'max_length': '${model.config_kwargs.max_position_embeddings}', 'is_truncation_random': True}, 'tokenizer': {'path_to_code_2_int': '/home/hf_ehr/code_2_int.json', 'path_to_code_2_count': '/home/hf_ehr/code_2_count.json', 'min_code_count': None}}, 'trainer': {'accumulate_grad_batches': 8, 'gradient_clip_value': 3, 'gradient_clip_algorithm': 'norm', 'devices': [0, 1, 2, 3], 'distributed_backend': 'ddp', 'is_use_bf16': False, 'is_use_fp16': True, 'min_epochs': 1, 'max_epochs': 1000, 'limit_train_batches': None, 'limit_val_batches': None, 'val_check_interval': 0.25, 'optimizer': {'lr': 0.0001}, 'scheduler': {'num_warmup_steps': 50000, 'num_decay_steps': 4000000, 'initial_lr': 3e-06, 'final_lr': 3e-05}, 'mlm_mask_pct': 0.15}, 'logging': {'wandb': {'is_wandb': True, 'name': 'bert-large'}, 'mlflow': {'is_mlflow': False, 'name': None}, 'is_log_grad_norm': False, 'log_every_n_steps': 1}, 'model': {'name': 'bert', 'hf_name': 'bert-base-uncased', 'config_kwargs': {'num_hidden_layers': 24, 'num_attention_heads': 16, 'hidden_size': 1024, 'max_position_embeddings': 1024}}}
2024-04-04 09:30:30.379 | INFO     | __main__:main:119 - {'main': {'seed': 1, 'path_to_output_dir': '/share/pi/nigam/mwornow/hf_ehr/cache/runs/bert-large/'}, 'callbacks': {'early_stopping': {'metric_mode': 'min', 'patience': 3}, 'model_checkpointing': {'save_top_k': 1, 'save_most_recent_k': 1, 'most_recent_every_n_train_steps': 5000, 'every_n_train_steps': 10000}}, 'data': {'dataset': {'path_to_femr_extract': '/home/hf_ehr/som-rit-phi-starr-prod.starr_omop_cdm5_deid_2023_08_13_extract_v9_lite'}, 'dataloader': {'batch_size': 2, 'n_workers': 4, 'max_length': '${model.config_kwargs.max_position_embeddings}', 'is_truncation_random': True}, 'tokenizer': {'path_to_code_2_int': '/home/hf_ehr/code_2_int.json', 'path_to_code_2_count': '/home/hf_ehr/code_2_count.json', 'min_code_count': None}}, 'trainer': {'accumulate_grad_batches': 8, 'gradient_clip_value': 3, 'gradient_clip_algorithm': 'norm', 'devices': [0, 1, 2, 3], 'distributed_backend': 'ddp', 'is_use_bf16': False, 'is_use_fp16': True, 'min_epochs': 1, 'max_epochs': 1000, 'limit_train_batches': None, 'limit_val_batches': None, 'val_check_interval': 0.25, 'optimizer': {'lr': 0.0001}, 'scheduler': {'num_warmup_steps': 50000, 'num_decay_steps': 4000000, 'initial_lr': 3e-06, 'final_lr': 3e-05}, 'mlm_mask_pct': 0.15}, 'logging': {'wandb': {'is_wandb': True, 'name': 'bert-large'}, 'mlflow': {'is_mlflow': False, 'name': None}, 'is_log_grad_norm': False, 'log_every_n_steps': 1}, 'model': {'name': 'bert', 'hf_name': 'bert-base-uncased', 'config_kwargs': {'num_hidden_layers': 24, 'num_attention_heads': 16, 'hidden_size': 1024, 'max_position_embeddings': 1024}}}
Loading data from local-scratch: `/home/hf_ehr/`.
{'main': {'seed': 1, 'path_to_output_dir': '/share/pi/nigam/mwornow/hf_ehr/cache/runs/bert-large/'}, 'callbacks': {'early_stopping': {'metric_mode': 'min', 'patience': 3}, 'model_checkpointing': {'save_top_k': 1, 'save_most_recent_k': 1, 'most_recent_every_n_train_steps': 5000, 'every_n_train_steps': 10000}}, 'data': {'dataset': {'path_to_femr_extract': '/home/hf_ehr/som-rit-phi-starr-prod.starr_omop_cdm5_deid_2023_08_13_extract_v9_lite'}, 'dataloader': {'batch_size': 2, 'n_workers': 4, 'max_length': '${model.config_kwargs.max_position_embeddings}', 'is_truncation_random': True}, 'tokenizer': {'path_to_code_2_int': '/home/hf_ehr/code_2_int.json', 'path_to_code_2_count': '/home/hf_ehr/code_2_count.json', 'min_code_count': None}}, 'trainer': {'accumulate_grad_batches': 8, 'gradient_clip_value': 3, 'gradient_clip_algorithm': 'norm', 'devices': [0, 1, 2, 3], 'distributed_backend': 'ddp', 'is_use_bf16': False, 'is_use_fp16': True, 'min_epochs': 1, 'max_epochs': 1000, 'limit_train_batches': None, 'limit_val_batches': None, 'val_check_interval': 0.25, 'optimizer': {'lr': 0.0001}, 'scheduler': {'num_warmup_steps': 50000, 'num_decay_steps': 4000000, 'initial_lr': 3e-06, 'final_lr': 3e-05}, 'mlm_mask_pct': 0.15}, 'logging': {'wandb': {'is_wandb': True, 'name': 'bert-large'}, 'mlflow': {'is_mlflow': False, 'name': None}, 'is_log_grad_norm': False, 'log_every_n_steps': 1}, 'model': {'name': 'bert', 'hf_name': 'bert-base-uncased', 'config_kwargs': {'num_hidden_layers': 24, 'num_attention_heads': 16, 'hidden_size': 1024, 'max_position_embeddings': 1024}}}
[2024-04-04 09:30:30,903][wandb.util][WARNING] - Unable to read the token file at /var/run/secrets/kubernetes.io/serviceaccount/token due to permission error ([Errno 13] Permission denied: '/var/run/secrets/kubernetes.io/serviceaccount/token').The current user id is 1300068. Consider changing the securityContext to run the container as the current user.
wandb: WARNING Unable to read the token file at /var/run/secrets/kubernetes.io/serviceaccount/token due to permission error ([Errno 13] Permission denied: '/var/run/secrets/kubernetes.io/serviceaccount/token').The current user id is 1300068. Consider changing the securityContext to run the container as the current user.
Loading data from local-scratch: `/home/hf_ehr/`.
{'main': {'seed': 1, 'path_to_output_dir': '/share/pi/nigam/mwornow/hf_ehr/cache/runs/bert-large/'}, 'callbacks': {'early_stopping': {'metric_mode': 'min', 'patience': 3}, 'model_checkpointing': {'save_top_k': 1, 'save_most_recent_k': 1, 'most_recent_every_n_train_steps': 5000, 'every_n_train_steps': 10000}}, 'data': {'dataset': {'path_to_femr_extract': '/home/hf_ehr/som-rit-phi-starr-prod.starr_omop_cdm5_deid_2023_08_13_extract_v9_lite'}, 'dataloader': {'batch_size': 2, 'n_workers': 4, 'max_length': '${model.config_kwargs.max_position_embeddings}', 'is_truncation_random': True}, 'tokenizer': {'path_to_code_2_int': '/home/hf_ehr/code_2_int.json', 'path_to_code_2_count': '/home/hf_ehr/code_2_count.json', 'min_code_count': None}}, 'trainer': {'accumulate_grad_batches': 8, 'gradient_clip_value': 3, 'gradient_clip_algorithm': 'norm', 'devices': [0, 1, 2, 3], 'distributed_backend': 'ddp', 'is_use_bf16': False, 'is_use_fp16': True, 'min_epochs': 1, 'max_epochs': 1000, 'limit_train_batches': None, 'limit_val_batches': None, 'val_check_interval': 0.25, 'optimizer': {'lr': 0.0001}, 'scheduler': {'num_warmup_steps': 50000, 'num_decay_steps': 4000000, 'initial_lr': 3e-06, 'final_lr': 3e-05}, 'mlm_mask_pct': 0.15}, 'logging': {'wandb': {'is_wandb': True, 'name': 'bert-large'}, 'mlflow': {'is_mlflow': False, 'name': None}, 'is_log_grad_norm': False, 'log_every_n_steps': 1}, 'model': {'name': 'bert', 'hf_name': 'bert-base-uncased', 'config_kwargs': {'num_hidden_layers': 24, 'num_attention_heads': 16, 'hidden_size': 1024, 'max_position_embeddings': 1024}}}
[2024-04-04 09:30:30,958][wandb.util][WARNING] - Unable to read the token file at /var/run/secrets/kubernetes.io/serviceaccount/token due to permission error ([Errno 13] Permission denied: '/var/run/secrets/kubernetes.io/serviceaccount/token').The current user id is 1300068. Consider changing the securityContext to run the container as the current user.
wandb: WARNING Unable to read the token file at /var/run/secrets/kubernetes.io/serviceaccount/token due to permission error ([Errno 13] Permission denied: '/var/run/secrets/kubernetes.io/serviceaccount/token').The current user id is 1300068. Consider changing the securityContext to run the container as the current user.
Loading data from local-scratch: `/home/hf_ehr/`.
{'main': {'seed': 1, 'path_to_output_dir': '/share/pi/nigam/mwornow/hf_ehr/cache/runs/bert-large/'}, 'callbacks': {'early_stopping': {'metric_mode': 'min', 'patience': 3}, 'model_checkpointing': {'save_top_k': 1, 'save_most_recent_k': 1, 'most_recent_every_n_train_steps': 5000, 'every_n_train_steps': 10000}}, 'data': {'dataset': {'path_to_femr_extract': '/home/hf_ehr/som-rit-phi-starr-prod.starr_omop_cdm5_deid_2023_08_13_extract_v9_lite'}, 'dataloader': {'batch_size': 2, 'n_workers': 4, 'max_length': '${model.config_kwargs.max_position_embeddings}', 'is_truncation_random': True}, 'tokenizer': {'path_to_code_2_int': '/home/hf_ehr/code_2_int.json', 'path_to_code_2_count': '/home/hf_ehr/code_2_count.json', 'min_code_count': None}}, 'trainer': {'accumulate_grad_batches': 8, 'gradient_clip_value': 3, 'gradient_clip_algorithm': 'norm', 'devices': [0, 1, 2, 3], 'distributed_backend': 'ddp', 'is_use_bf16': False, 'is_use_fp16': True, 'min_epochs': 1, 'max_epochs': 1000, 'limit_train_batches': None, 'limit_val_batches': None, 'val_check_interval': 0.25, 'optimizer': {'lr': 0.0001}, 'scheduler': {'num_warmup_steps': 50000, 'num_decay_steps': 4000000, 'initial_lr': 3e-06, 'final_lr': 3e-05}, 'mlm_mask_pct': 0.15}, 'logging': {'wandb': {'is_wandb': True, 'name': 'bert-large'}, 'mlflow': {'is_mlflow': False, 'name': None}, 'is_log_grad_norm': False, 'log_every_n_steps': 1}, 'model': {'name': 'bert', 'hf_name': 'bert-base-uncased', 'config_kwargs': {'num_hidden_layers': 24, 'num_attention_heads': 16, 'hidden_size': 1024, 'max_position_embeddings': 1024}}}
[2024-04-04 09:30:30,966][wandb.util][WARNING] - Unable to read the token file at /var/run/secrets/kubernetes.io/serviceaccount/token due to permission error ([Errno 13] Permission denied: '/var/run/secrets/kubernetes.io/serviceaccount/token').The current user id is 1300068. Consider changing the securityContext to run the container as the current user.
wandb: WARNING Unable to read the token file at /var/run/secrets/kubernetes.io/serviceaccount/token due to permission error ([Errno 13] Permission denied: '/var/run/secrets/kubernetes.io/serviceaccount/token').The current user id is 1300068. Consider changing the securityContext to run the container as the current user.
wandb: Currently logged in as: miking98 (ehr-fm). Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: miking98 (ehr-fm). Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: miking98 (ehr-fm). Use `wandb login --relogin` to force relogin
wandb: wandb version 0.16.6 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.11
wandb: Run data is saved locally in /share/pi/nigam/mwornow/wandb_cache/wandb/run-20240404_093031-ssmtte6u
wandb: Run `wandb offline` to turn off syncing.
wandb: wandb version 0.16.6 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.11
wandb: Run data is saved locally in /share/pi/nigam/mwornow/wandb_cache/wandb/run-20240404_093031-ozs82ewm
wandb: Run `wandb offline` to turn off syncing.
wandb: wandb version 0.16.6 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.11
wandb: Run data is saved locally in /share/pi/nigam/mwornow/wandb_cache/wandb/run-20240404_093031-350llll4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run leafy-resonance-104
wandb: ⭐️ View project at https://wandb.ai/ehr-fm/hf_ehr-hf_ehr_scripts
wandb: 🚀 View run at https://wandb.ai/ehr-fm/hf_ehr-hf_ehr_scripts/runs/ssmtte6u
wandb: Syncing run grateful-darkness-104
wandb: ⭐️ View project at https://wandb.ai/ehr-fm/hf_ehr-hf_ehr_scripts
wandb: 🚀 View run at https://wandb.ai/ehr-fm/hf_ehr-hf_ehr_scripts/runs/ozs82ewm
wandb: Syncing run fragrant-blaze-104
wandb: ⭐️ View project at https://wandb.ai/ehr-fm/hf_ehr-hf_ehr_scripts
wandb: 🚀 View run at https://wandb.ai/ehr-fm/hf_ehr-hf_ehr_scripts/runs/350llll4
2024-04-04 09:30:38.594 | INFO     | __main__:main:194 - ========================== Starting main ==========================
2024-04-04 09:30:38.595 | INFO     | __main__:main:195 - >>>> Training from SCRATCH | Saving to: `/share/pi/nigam/mwornow/hf_ehr/cache/runs/bert-large/` <<<<
2024-04-04 09:30:38.595 | INFO     | __main__:main:198 - Loading tokenizer: `/home/hf_ehr/code_2_int.json`
2024-04-04 09:30:38.609 | INFO     | __main__:main:194 - ========================== Starting main ==========================
2024-04-04 09:30:38.610 | INFO     | __main__:main:195 - >>>> Training from SCRATCH | Saving to: `/share/pi/nigam/mwornow/hf_ehr/cache/runs/bert-large/` <<<<
2024-04-04 09:30:38.610 | INFO     | __main__:main:198 - Loading tokenizer: `/home/hf_ehr/code_2_int.json`
2024-04-04 09:30:38.610 | INFO     | __main__:main:194 - ========================== Starting main ==========================
2024-04-04 09:30:38.611 | INFO     | __main__:main:195 - >>>> Training from SCRATCH | Saving to: `/share/pi/nigam/mwornow/hf_ehr/cache/runs/bert-large/` <<<<
2024-04-04 09:30:38.611 | INFO     | __main__:main:198 - Loading tokenizer: `/home/hf_ehr/code_2_int.json`
2024-04-04 09:30:38.812 | INFO     | __main__:main:202 - Vocab size: `167238`
2024-04-04 09:30:38.814 | INFO     | __main__:main:205 - Loading model: `bert`
[2024-04-04 09:30:38,829][torch.distributed.nn.jit.instantiator][INFO] - Created a temporary directory at /tmp/tmplny_kch9
[2024-04-04 09:30:38,830][torch.distributed.nn.jit.instantiator][INFO] - Writing /tmp/tmplny_kch9/_remote_module_non_scriptable.py
2024-04-04 09:30:38.837 | INFO     | __main__:main:202 - Vocab size: `167238`
2024-04-04 09:30:38.839 | INFO     | __main__:main:205 - Loading model: `bert`
2024-04-04 09:30:38.840 | INFO     | __main__:main:202 - Vocab size: `167238`
2024-04-04 09:30:38.841 | INFO     | __main__:main:205 - Loading model: `bert`
[2024-04-04 09:30:38,854][torch.distributed.nn.jit.instantiator][INFO] - Created a temporary directory at /tmp/tmplbjr8kcl
[2024-04-04 09:30:38,854][torch.distributed.nn.jit.instantiator][INFO] - Created a temporary directory at /tmp/tmpq0xhmctj
[2024-04-04 09:30:38,854][torch.distributed.nn.jit.instantiator][INFO] - Writing /tmp/tmplbjr8kcl/_remote_module_non_scriptable.py
[2024-04-04 09:30:38,855][torch.distributed.nn.jit.instantiator][INFO] - Writing /tmp/tmpq0xhmctj/_remote_module_non_scriptable.py
2024-04-04 09:30:47.783 | INFO     | __main__:main:219 - Parameter count of model = 595511296
2024-04-04 09:30:47.786 | INFO     | __main__:main:222 - Loading FEMR datasets...
2024-04-04 09:30:48.025 | INFO     | __main__:main:219 - Parameter count of model = 595511296
2024-04-04 09:30:48.028 | INFO     | __main__:main:222 - Loading FEMR datasets...
2024-04-04 09:30:48.184 | INFO     | __main__:main:219 - Parameter count of model = 595511296
2024-04-04 09:30:48.187 | INFO     | __main__:main:222 - Loading FEMR datasets...
2024-04-04 09:31:11.492 | INFO     | __main__:main:226 - Loading FEMR dataloaders...
[rank: 3] Seed set to 1
Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4
[W socket.cpp:601] [c10d] The client socket cannot be initialized to connect to [localhost]:37627 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:601] [c10d] The client socket cannot be initialized to connect to [localhost]:37627 (errno: 97 - Address family not supported by protocol).
[2024-04-04 09:31:12,109][torch.distributed.distributed_c10d][INFO] - Added key: store_based_barrier_key:1 to store for rank: 3
2024-04-04 09:31:13.403 | INFO     | __main__:main:226 - Loading FEMR dataloaders...
2024-04-04 09:31:13.484 | INFO     | __main__:main:226 - Loading FEMR dataloaders...
[rank: 2] Seed set to 1
Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4
[W socket.cpp:601] [c10d] The client socket cannot be initialized to connect to [localhost]:37627 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:601] [c10d] The client socket cannot be initialized to connect to [localhost]:37627 (errno: 97 - Address family not supported by protocol).
[2024-04-04 09:31:14,036][torch.distributed.distributed_c10d][INFO] - Added key: store_based_barrier_key:1 to store for rank: 2
[rank: 1] Seed set to 1
Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4
[W socket.cpp:601] [c10d] The client socket cannot be initialized to connect to [localhost]:37627 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:601] [c10d] The client socket cannot be initialized to connect to [localhost]:37627 (errno: 97 - Address family not supported by protocol).
[2024-04-04 09:31:14,070][torch.distributed.distributed_c10d][INFO] - Added key: store_based_barrier_key:1 to store for rank: 1
[W socket.cpp:601] [c10d] The client socket cannot be initialized to connect to [localhost]:37627 (errno: 97 - Address family not supported by protocol).
[2024-04-04 09:31:14,081][torch.distributed.distributed_c10d][INFO] - Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
[2024-04-04 09:31:14,080][torch.distributed.distributed_c10d][INFO] - Added key: store_based_barrier_key:1 to store for rank: 0
[2024-04-04 09:31:14,083][torch.distributed.distributed_c10d][INFO] - Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
----------------------------------------------------------------------------------------------------
distributed_backend=nccl
All distributed processes registered. Starting with 4 processes
----------------------------------------------------------------------------------------------------

[2024-04-04 09:31:14,088][torch.distributed.distributed_c10d][INFO] - Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
[2024-04-04 09:31:14,087][torch.distributed.distributed_c10d][INFO] - Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
/home/hf_ehr/hf_env/lib/python3.10/site-packages/lightning/pytorch/loggers/wandb.py:391: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.
LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]

  | Name        | Type       | Params
-------------------------------------------
0 | sum_metrics | ModuleDict | 0     
1 | model       | BertModel  | 424 M 
2 | lm_head     | Linear     | 171 M 
-------------------------------------------
595 M     Trainable params
0         Non-trainable params
595 M     Total params
2,382.045 Total estimated model params size (MB)
Sanity Checking: |          | 0/? [00:00<?, ?it/s]Sanity Checking:   0%|          | 0/2 [00:00<?, ?it/s]Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]Sanity Checking DataLoader 0:  50%|█████     | 1/2 [00:00<00:00,  1.42it/s]Sanity Checking DataLoader 0: 100%|██████████| 2/2 [00:00<00:00,  2.52it/s]                                                                           Training: |          | 0/? [00:00<?, ?it/s]Training:   0%|          | 0/329756 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/329756 [00:00<?, ?it/s] /home/mwornow/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:139: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
/home/mwornow/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:139: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
/home/mwornow/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:139: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
/home/mwornow/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:139: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
Epoch 0:   0%|          | 1/329756 [00:00<35:52:53,  2.55it/s]Epoch 0:   0%|          | 1/329756 [00:00<35:59:11,  2.55it/s, v_num=xdvf, train/loss=12.10]Epoch 0:   0%|          | 2/329756 [00:00<30:58:28,  2.96it/s, v_num=xdvf, train/loss=12.10]Epoch 0:   0%|          | 2/329756 [00:00<31:02:08,  2.95it/s, v_num=xdvf, train/loss=12.30]Epoch 0:   0%|          | 3/329756 [00:00<28:30:43,  3.21it/s, v_num=xdvf, train/loss=12.30]Epoch 0:   0%|          | 3/329756 [00:00<28:33:28,  3.21it/s, v_num=xdvf, train/loss=12.10]Epoch 0:   0%|          | 4/329756 [00:01<27:27:46,  3.34it/s, v_num=xdvf, train/loss=12.10]Epoch 0:   0%|          | 4/329756 [00:01<27:29:44,  3.33it/s, v_num=xdvf, train/loss=12.50]Epoch 0:   0%|          | 5/329756 [00:01<26:56:22,  3.40it/s, v_num=xdvf, train/loss=12.50]Epoch 0:   0%|          | 5/329756 [00:01<28:15:54,  3.24it/s, v_num=xdvf, train/loss=12.30]Epoch 0:   0%|          | 6/329756 [00:01<27:05:06,  3.38it/s, v_num=xdvf, train/loss=12.30]Epoch 0:   0%|          | 6/329756 [00:01<28:10:30,  3.25it/s, v_num=xdvf, train/loss=12.10]Epoch 0:   0%|          | 7/329756 [00:02<26:44:27,  3.43it/s, v_num=xdvf, train/loss=12.10]Epoch 0:   0%|          | 7/329756 [00:02<26:45:34,  3.42it/s, v_num=xdvf, train/loss=12.20]Epoch 0:   0%|          | 8/329756 [00:02<28:21:46,  3.23it/s, v_num=xdvf, train/loss=12.20]Epoch 0:   0%|          | 8/329756 [00:02<28:56:17,  3.17it/s, v_num=xdvf, train/loss=12.10][2024-04-04 09:32:32,245][torch.nn.parallel.distributed][INFO] - Reducer buckets have been rebuilt in this iteration.
[2024-04-04 09:32:32,245][torch.nn.parallel.distributed][INFO] - Reducer buckets have been rebuilt in this iteration.
[2024-04-04 09:32:32,245][torch.nn.parallel.distributed][INFO] - Reducer buckets have been rebuilt in this iteration.
[2024-04-04 09:32:32,246][torch.nn.parallel.distributed][INFO] - Reducer buckets have been rebuilt in this iteration.
Epoch 0:   0%|          | 9/329756 [00:03<38:05:06,  2.41it/s, v_num=xdvf, train/loss=12.10]Epoch 0:   0%|          | 9/329756 [00:03<38:43:41,  2.37it/s, v_num=xdvf, train/loss=12.00]Epoch 0:   0%|          | 10/329756 [00:03<36:37:39,  2.50it/s, v_num=xdvf, train/loss=12.00]Epoch 0:   0%|          | 10/329756 [00:04<36:38:40,  2.50it/s, v_num=xdvf, train/loss=12.00]Epoch 0:   0%|          | 11/329756 [00:04<35:25:49,  2.59it/s, v_num=xdvf, train/loss=12.00]Epoch 0:   0%|          | 11/329756 [00:04<36:01:57,  2.54it/s, v_num=xdvf, train/loss=12.20]Epoch 0:   0%|          | 12/329756 [00:04<34:26:09,  2.66it/s, v_num=xdvf, train/loss=12.20]Epoch 0:   0%|          | 12/329756 [00:04<34:49:32,  2.63it/s, v_num=xdvf, train/loss=12.10]Epoch 0:   0%|          | 13/329756 [00:04<33:48:27,  2.71it/s, v_num=xdvf, train/loss=12.10]Epoch 0:   0%|          | 13/329756 [00:04<33:48:57,  2.71it/s, v_num=xdvf, train/loss=12.10]Epoch 0:   0%|          | 14/329756 [00:05<33:31:18,  2.73it/s, v_num=xdvf, train/loss=12.10]Epoch 0:   0%|          | 14/329756 [00:05<34:00:08,  2.69it/s, v_num=xdvf, train/loss=12.20]Epoch 0:   0%|          | 15/329756 [00:05<33:14:23,  2.76it/s, v_num=xdvf, train/loss=12.20]Epoch 0:   0%|          | 15/329756 [00:05<33:41:04,  2.72it/s, v_num=xdvf, train/loss=12.10]Epoch 0:   0%|          | 16/329756 [00:05<33:44:21,  2.71it/s, v_num=xdvf, train/loss=12.10]Epoch 0:   0%|          | 16/329756 [00:05<34:03:10,  2.69it/s, v_num=xdvf, train/loss=12.10]Epoch 0:   0%|          | 17/329756 [00:06<33:15:15,  2.75it/s, v_num=xdvf, train/loss=12.10]Epoch 0:   0%|          | 17/329756 [00:06<33:17:44,  2.75it/s, v_num=xdvf, train/loss=12.20]/home/hf_ehr/hf_env/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py:132: `training_step` returned `None`. If this was on purpose, ignore this warning...
Epoch 0:   0%|          | 18/329756 [00:06<32:01:52,  2.86it/s, v_num=xdvf, train/loss=12.20]Epoch 0:   0%|          | 18/329756 [00:06<32:03:51,  2.86it/s, v_num=xdvf, train/loss=12.20]Epoch 0:   0%|          | 19/329756 [00:06<31:31:17,  2.91it/s, v_num=xdvf, train/loss=12.20]Epoch 0:   0%|          | 19/329756 [00:06<31:52:25,  2.87it/s, v_num=xdvf, train/loss=12.00]Epoch 0:   0%|          | 20/329756 [00:06<31:14:23,  2.93it/s, v_num=xdvf, train/loss=12.00]Epoch 0:   0%|          | 20/329756 [00:07<32:44:10,  2.80it/s, v_num=xdvf, train/loss=12.10]Epoch 0:   0%|          | 21/329756 [00:07<32:14:07,  2.84it/s, v_num=xdvf, train/loss=12.10]Epoch 0:   0%|          | 21/329756 [00:07<32:33:38,  2.81it/s, v_num=xdvf, train/loss=12.00]Epoch 0:   0%|          | 22/329756 [00:07<31:59:24,  2.86it/s, v_num=xdvf, train/loss=12.00]Epoch 0:   0%|          | 22/329756 [00:07<32:16:22,  2.84it/s, v_num=xdvf, train/loss=12.10]Epoch 0:   0%|          | 23/329756 [00:07<31:33:49,  2.90it/s, v_num=xdvf, train/loss=12.10]Epoch 0:   0%|          | 23/329756 [00:07<31:35:46,  2.90it/s, v_num=xdvf, train/loss=12.30]